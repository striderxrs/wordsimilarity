{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b887e444",
   "metadata": {},
   "source": [
    "##### Problem - To detect if two job titles are similar or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346b8d41",
   "metadata": {},
   "source": [
    "There are 3 different models with training parameters in this script. It would be ideal to comment out the ones you don't need.\n",
    "\n",
    "First method is using Word2Vec - training word2vec on a new model with a dataset containing ~300,000 job titles. Accuracy is very bad\n",
    "\n",
    "Second method is using Word2Vec but with the GoogleNews pre trained model. Good Accuracy but only for individual words.\n",
    "\n",
    "Third method is using Doc2Vec and the same dataset with training. Yields the best results so far.\n",
    "\n",
    "\n",
    "All models at the end of training has been saved to working directory and can be loaded again with their respective methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e598fe",
   "metadata": {},
   "source": [
    "###### First Method - Using Word2Vec custom model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5e169f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "from collections import defaultdict\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "604400dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#$ pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "165a8914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbd303ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find current working directory\n",
    "directory = os.getcwd()\n",
    "\n",
    "# specifying csv filename, this is a switch between two datasets in the directory.\n",
    "\n",
    "# filename = \"\\\\job_title.csv\"\n",
    "filename = \"\\\\titles_final.csv\"\n",
    "\n",
    "# using concat to generate fullpath\n",
    "file = directory+filename\n",
    "\n",
    "# load csv file containing job titles\n",
    "df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed26c9a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Titles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Product Manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Solutions Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Staff Software Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Head of Product (Platform)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Incubation Lead  Success Cloud</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298391</th>\n",
       "      <td>IT Analyst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298392</th>\n",
       "      <td>Concertmaster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298393</th>\n",
       "      <td>Technical Lead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298394</th>\n",
       "      <td>Sales Associate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298395</th>\n",
       "      <td>Chair at Model United Nations at the Liberal A...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>298396 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Titles\n",
       "0                                  Senior Product Manager\n",
       "1                                      Solutions Engineer\n",
       "2                                 Staff Software Engineer\n",
       "3                              Head of Product (Platform)\n",
       "4                          Incubation Lead  Success Cloud\n",
       "...                                                   ...\n",
       "298391                                         IT Analyst\n",
       "298392                                      Concertmaster\n",
       "298393                                     Technical Lead\n",
       "298394                                    Sales Associate\n",
       "298395  Chair at Model United Nations at the Liberal A...\n",
       "\n",
       "[298396 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a little data refactoring step\n",
    "\n",
    "df.isnull().sum()\n",
    "df.dropna()\n",
    "\n",
    "# this could be optional - in a future step, vocab should only consider unique words\n",
    "# df = df.drop_duplicates(keep='first', inplace=False, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb61d78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization\n",
    "\n",
    "# filter_lowercase = df['Titles'].str.lower()\n",
    "\n",
    "df_sentences = df['Titles'].astype('str').tolist()\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "df_tokenized = [w.lower() for w in df_sentences]\n",
    "# df_tokenized = [tokenizer.tokenize(i) for i in df_tokenized]\n",
    "\n",
    "# removing punctuations and extra spacing between words\n",
    "\n",
    "# df[\"Titles\"] = filter_lowercase.str.replace('[^\\w\\s]', '')\n",
    "# df[\"Titles\"] = filter_lowercase.str.replace('\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87e38c7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['solutions engineer',\n",
       " 'staff software engineer',\n",
       " 'head of product (platform)',\n",
       " 'incubation lead  success cloud',\n",
       " 'author',\n",
       " 'technical writer',\n",
       " 'product',\n",
       " 'technology architecture and operations',\n",
       " 'software engineer']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokenized[1:10] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29a40357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['solutions engineer'],\n",
       " ['staff software engineer'],\n",
       " ['head of product (platform)'],\n",
       " ['incubation lead  success cloud'],\n",
       " ['author'],\n",
       " ['technical writer'],\n",
       " ['product'],\n",
       " ['technology architecture and operations'],\n",
       " ['software engineer']]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting each element into it's own list - doing this because we need individual job title as its own list\n",
    "\n",
    "\n",
    "def listoflists(inputlist):\n",
    "    return [[el] for el in inputlist]\n",
    "\n",
    "nestedlist = listoflists(df_tokenized)\n",
    "\n",
    "# reinitializing the dataset again\n",
    "\n",
    "# df = pd.DataFrame({'Titles':nestedlist})\n",
    "nestedlist[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d218a9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phrases, Phraser, bigram\n",
    "\n",
    "from gensim.models.phrases import Phrases, Phraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c2bae012",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 20:53:51: collecting all words and their counts\n",
      "INFO - 20:53:51: PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "INFO - 20:53:51: PROGRESS: at sentence #10000, processed 10000 words and 5996 word types\n",
      "INFO - 20:53:51: PROGRESS: at sentence #20000, processed 20000 words and 10906 word types\n",
      "INFO - 20:53:51: PROGRESS: at sentence #30000, processed 30000 words and 15154 word types\n",
      "INFO - 20:53:51: PROGRESS: at sentence #40000, processed 40000 words and 18746 word types\n",
      "INFO - 20:53:51: PROGRESS: at sentence #50000, processed 50000 words and 21926 word types\n",
      "INFO - 20:53:51: PROGRESS: at sentence #60000, processed 60000 words and 26699 word types\n",
      "INFO - 20:53:51: PROGRESS: at sentence #70000, processed 70000 words and 31341 word types\n",
      "INFO - 20:53:51: PROGRESS: at sentence #80000, processed 80000 words and 35600 word types\n",
      "INFO - 20:53:51: PROGRESS: at sentence #90000, processed 90000 words and 39443 word types\n",
      "INFO - 20:53:51: PROGRESS: at sentence #100000, processed 100000 words and 43159 word types\n",
      "INFO - 20:53:51: PROGRESS: at sentence #110000, processed 110000 words and 47536 word types\n",
      "INFO - 20:53:51: PROGRESS: at sentence #120000, processed 120000 words and 51911 word types\n",
      "INFO - 20:53:51: PROGRESS: at sentence #130000, processed 130000 words and 56047 word types\n",
      "INFO - 20:53:51: PROGRESS: at sentence #140000, processed 140000 words and 59770 word types\n",
      "INFO - 20:53:51: PROGRESS: at sentence #150000, processed 150000 words and 63472 word types\n",
      "INFO - 20:53:51: PROGRESS: at sentence #160000, processed 160000 words and 67515 word types\n",
      "INFO - 20:53:51: PROGRESS: at sentence #170000, processed 170000 words and 71473 word types\n",
      "INFO - 20:53:51: PROGRESS: at sentence #180000, processed 180000 words and 75269 word types\n",
      "INFO - 20:53:51: PROGRESS: at sentence #190000, processed 190000 words and 78998 word types\n",
      "INFO - 20:53:51: PROGRESS: at sentence #200000, processed 200000 words and 82853 word types\n",
      "INFO - 20:53:51: PROGRESS: at sentence #210000, processed 210000 words and 86706 word types\n",
      "INFO - 20:53:51: PROGRESS: at sentence #220000, processed 220000 words and 90433 word types\n",
      "INFO - 20:53:51: PROGRESS: at sentence #230000, processed 230000 words and 94223 word types\n",
      "INFO - 20:53:51: PROGRESS: at sentence #240000, processed 240000 words and 97957 word types\n",
      "INFO - 20:53:51: PROGRESS: at sentence #250000, processed 250000 words and 101646 word types\n",
      "INFO - 20:53:51: PROGRESS: at sentence #260000, processed 260000 words and 105407 word types\n",
      "INFO - 20:53:51: PROGRESS: at sentence #270000, processed 270000 words and 109135 word types\n",
      "INFO - 20:53:51: PROGRESS: at sentence #280000, processed 280000 words and 112884 word types\n",
      "INFO - 20:53:51: PROGRESS: at sentence #290000, processed 290000 words and 116712 word types\n",
      "INFO - 20:53:51: collected 120044 token types (unigram + bigrams) from a corpus of 298396 words and 298396 sentences\n",
      "INFO - 20:53:51: merged Phrases<120044 vocab, min_count=2, threshold=10.0, max_vocab_size=40000000>\n",
      "INFO - 20:53:51: Phrases lifecycle event {'msg': 'built Phrases<120044 vocab, min_count=2, threshold=10.0, max_vocab_size=40000000> in 0.19s', 'datetime': '2021-11-15T20:53:51.697146', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "phrases = Phrases(nestedlist, min_count=2, progress_per=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "014dc8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 20:53:54: exporting phrases from Phrases<120044 vocab, min_count=2, threshold=10.0, max_vocab_size=40000000>\n",
      "INFO - 20:53:54: FrozenPhrases lifecycle event {'msg': 'exported FrozenPhrases<0 phrases, min_count=2, threshold=10.0> from Phrases<120044 vocab, min_count=2, threshold=10.0, max_vocab_size=40000000> in 0.03s', 'datetime': '2021-11-15T20:53:54.640178', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "bigram = Phraser(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "084c7574",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_sentences = bigram[nestedlist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d2a9fae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the model\n",
    "\n",
    "import multiprocessing\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d2d48557",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 20:54:01: Word2Vec lifecycle event {'params': 'Word2Vec(vocab=0, vector_size=300, alpha=0.03)', 'datetime': '2021-11-15T20:54:01.212172', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "# parameters for the model\n",
    "\n",
    "model = Word2Vec(min_count=1, \n",
    "                 window=4, \n",
    "                 vector_size=300, \n",
    "                 sample=0, \n",
    "                 sg=0, \n",
    "                 alpha=0.03, \n",
    "                 min_alpha=0.0007, \n",
    "                 negative=5, \n",
    "                 workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c291c3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 20:54:36: collecting all words and their counts\n",
      "INFO - 20:54:36: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 20:54:36: PROGRESS: at sentence #10000, processed 10000 words, keeping 5996 word types\n",
      "INFO - 20:54:36: PROGRESS: at sentence #20000, processed 20000 words, keeping 10906 word types\n",
      "INFO - 20:54:36: PROGRESS: at sentence #30000, processed 30000 words, keeping 15154 word types\n",
      "INFO - 20:54:36: PROGRESS: at sentence #40000, processed 40000 words, keeping 18746 word types\n",
      "INFO - 20:54:36: PROGRESS: at sentence #50000, processed 50000 words, keeping 21926 word types\n",
      "INFO - 20:54:36: PROGRESS: at sentence #60000, processed 60000 words, keeping 26699 word types\n",
      "INFO - 20:54:36: PROGRESS: at sentence #70000, processed 70000 words, keeping 31341 word types\n",
      "INFO - 20:54:36: PROGRESS: at sentence #80000, processed 80000 words, keeping 35600 word types\n",
      "INFO - 20:54:36: PROGRESS: at sentence #90000, processed 90000 words, keeping 39443 word types\n",
      "INFO - 20:54:36: PROGRESS: at sentence #100000, processed 100000 words, keeping 43159 word types\n",
      "INFO - 20:54:36: PROGRESS: at sentence #110000, processed 110000 words, keeping 47536 word types\n",
      "INFO - 20:54:36: PROGRESS: at sentence #120000, processed 120000 words, keeping 51911 word types\n",
      "INFO - 20:54:36: PROGRESS: at sentence #130000, processed 130000 words, keeping 56047 word types\n",
      "INFO - 20:54:36: PROGRESS: at sentence #140000, processed 140000 words, keeping 59770 word types\n",
      "INFO - 20:54:36: PROGRESS: at sentence #150000, processed 150000 words, keeping 63472 word types\n",
      "INFO - 20:54:36: PROGRESS: at sentence #160000, processed 160000 words, keeping 67515 word types\n",
      "INFO - 20:54:36: PROGRESS: at sentence #170000, processed 170000 words, keeping 71473 word types\n",
      "INFO - 20:54:36: PROGRESS: at sentence #180000, processed 180000 words, keeping 75269 word types\n",
      "INFO - 20:54:36: PROGRESS: at sentence #190000, processed 190000 words, keeping 78998 word types\n",
      "INFO - 20:54:36: PROGRESS: at sentence #200000, processed 200000 words, keeping 82853 word types\n",
      "INFO - 20:54:36: PROGRESS: at sentence #210000, processed 210000 words, keeping 86706 word types\n",
      "INFO - 20:54:36: PROGRESS: at sentence #220000, processed 220000 words, keeping 90433 word types\n",
      "INFO - 20:54:36: PROGRESS: at sentence #230000, processed 230000 words, keeping 94223 word types\n",
      "INFO - 20:54:36: PROGRESS: at sentence #240000, processed 240000 words, keeping 97957 word types\n",
      "INFO - 20:54:36: PROGRESS: at sentence #250000, processed 250000 words, keeping 101646 word types\n",
      "INFO - 20:54:36: PROGRESS: at sentence #260000, processed 260000 words, keeping 105407 word types\n",
      "INFO - 20:54:36: PROGRESS: at sentence #270000, processed 270000 words, keeping 109135 word types\n",
      "INFO - 20:54:36: PROGRESS: at sentence #280000, processed 280000 words, keeping 112884 word types\n",
      "INFO - 20:54:36: PROGRESS: at sentence #290000, processed 290000 words, keeping 116712 word types\n",
      "INFO - 20:54:36: collected 120044 word types from a corpus of 298396 raw words and 298396 sentences\n",
      "INFO - 20:54:36: Creating a fresh vocabulary\n",
      "INFO - 20:54:37: Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 120044 unique words (100.0%% of original 120044, drops 0)', 'datetime': '2021-11-15T20:54:37.218537', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "INFO - 20:54:37: Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 298396 word corpus (100.0%% of original 298396, drops 0)', 'datetime': '2021-11-15T20:54:37.218537', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "INFO - 20:54:37: deleting the raw counts dictionary of 120044 items\n",
      "INFO - 20:54:37: sample=0 downsamples 0 most-common words\n",
      "INFO - 20:54:37: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 298396 word corpus (100.0%% of prior 298396)', 'datetime': '2021-11-15T20:54:37.850536', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "WARNING - 20:54:37: sorting after vectors have been allocated is expensive & error-prone\n",
      "INFO - 20:54:38: estimated required memory for 120044 words and 300 dimensions: 348127600 bytes\n",
      "INFO - 20:54:38: resetting layer weights\n",
      "INFO - 20:54:38: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-11-15T20:54:38.970539', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'build_vocab'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocab: 0.05 mins\n"
     ]
    }
   ],
   "source": [
    "# building vocabulary from dataset\n",
    "\n",
    "t=time()\n",
    "model.build_vocab(bigram_sentences, progress_per=10000)\n",
    "\n",
    "print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1ef967b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "298396"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "762d4e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 20:54:43: Word2Vec lifecycle event {'msg': 'training model with 4 workers on 120044 vocabulary and 300 features, using sg=0 hs=0 sample=0 negative=5 window=4', 'datetime': '2021-11-15T20:54:43.672500', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "INFO - 20:54:44: EPOCH 1 - PROGRESS: at 60.32% examples, 176700 words/s, in_qsize 7, out_qsize 0\n",
      "INFO - 20:54:44: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:54:44: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:54:44: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:54:44: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:54:44: EPOCH - 1 : training on 298396 raw words (298396 effective words) took 1.1s, 264210 effective words/s\n",
      "INFO - 20:54:45: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:54:45: EPOCH 2 - PROGRESS: at 93.84% examples, 278088 words/s, in_qsize 2, out_qsize 1\n",
      "INFO - 20:54:45: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:54:45: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:54:45: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:54:45: EPOCH - 2 : training on 298396 raw words (298396 effective words) took 1.0s, 294102 effective words/s\n",
      "INFO - 20:54:46: EPOCH 3 - PROGRESS: at 83.78% examples, 249408 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 20:54:46: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:54:46: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:54:46: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:54:46: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:54:46: EPOCH - 3 : training on 298396 raw words (298396 effective words) took 1.0s, 287720 effective words/s\n",
      "INFO - 20:54:47: EPOCH 4 - PROGRESS: at 87.13% examples, 259888 words/s, in_qsize 4, out_qsize 0\n",
      "INFO - 20:54:47: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:54:47: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:54:47: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:54:47: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:54:47: EPOCH - 4 : training on 298396 raw words (298396 effective words) took 1.0s, 290300 effective words/s\n",
      "INFO - 20:54:48: EPOCH 5 - PROGRESS: at 90.48% examples, 269961 words/s, in_qsize 3, out_qsize 1\n",
      "INFO - 20:54:48: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:54:48: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:54:48: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:54:48: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:54:48: EPOCH - 5 : training on 298396 raw words (298396 effective words) took 1.0s, 289182 effective words/s\n",
      "INFO - 20:54:49: EPOCH 6 - PROGRESS: at 87.13% examples, 258807 words/s, in_qsize 4, out_qsize 0\n",
      "INFO - 20:54:50: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:54:50: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:54:50: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:54:50: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:54:50: EPOCH - 6 : training on 298396 raw words (298396 effective words) took 1.0s, 285272 effective words/s\n",
      "INFO - 20:54:51: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:54:51: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:54:51: EPOCH 7 - PROGRESS: at 97.19% examples, 288056 words/s, in_qsize 1, out_qsize 1\n",
      "INFO - 20:54:51: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:54:51: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:54:51: EPOCH - 7 : training on 298396 raw words (298396 effective words) took 1.0s, 294457 effective words/s\n",
      "INFO - 20:54:52: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:54:52: EPOCH 8 - PROGRESS: at 93.84% examples, 275943 words/s, in_qsize 2, out_qsize 1\n",
      "INFO - 20:54:52: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:54:52: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:54:52: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:54:52: EPOCH - 8 : training on 298396 raw words (298396 effective words) took 1.0s, 292574 effective words/s\n",
      "INFO - 20:54:53: EPOCH 9 - PROGRESS: at 60.32% examples, 173891 words/s, in_qsize 7, out_qsize 0\n",
      "INFO - 20:54:53: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:54:53: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:54:53: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:54:53: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:54:53: EPOCH - 9 : training on 298396 raw words (298396 effective words) took 1.1s, 260908 effective words/s\n",
      "INFO - 20:54:54: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:54:54: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:54:54: EPOCH 10 - PROGRESS: at 96.65% examples, 288053 words/s, in_qsize 1, out_qsize 1\n",
      "INFO - 20:54:54: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:54:54: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:54:54: EPOCH - 10 : training on 298396 raw words (298396 effective words) took 1.0s, 296278 effective words/s\n",
      "INFO - 20:54:55: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:54:55: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:54:55: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:54:55: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:54:55: EPOCH - 11 : training on 298396 raw words (298396 effective words) took 1.0s, 301712 effective words/s\n",
      "INFO - 20:54:56: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:54:56: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:54:56: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:54:56: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:54:56: EPOCH - 12 : training on 298396 raw words (298396 effective words) took 1.0s, 301468 effective words/s\n",
      "INFO - 20:54:57: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:54:57: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:54:57: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:54:57: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:54:57: EPOCH - 13 : training on 298396 raw words (298396 effective words) took 0.9s, 314843 effective words/s\n",
      "INFO - 20:54:58: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:54:58: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:54:58: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:54:58: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:54:58: EPOCH - 14 : training on 298396 raw words (298396 effective words) took 1.0s, 304204 effective words/s\n",
      "INFO - 20:54:59: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:54:59: EPOCH 15 - PROGRESS: at 93.84% examples, 277149 words/s, in_qsize 2, out_qsize 1\n",
      "INFO - 20:54:59: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:54:59: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:54:59: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:54:59: EPOCH - 15 : training on 298396 raw words (298396 effective words) took 1.0s, 290671 effective words/s\n",
      "INFO - 20:55:00: EPOCH 16 - PROGRESS: at 73.73% examples, 214337 words/s, in_qsize 7, out_qsize 0\n",
      "INFO - 20:55:00: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:00: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:00: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:00: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:00: EPOCH - 16 : training on 298396 raw words (298396 effective words) took 1.1s, 271805 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 20:55:01: EPOCH 17 - PROGRESS: at 80.43% examples, 237551 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 20:55:01: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:01: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:01: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:01: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:01: EPOCH - 17 : training on 298396 raw words (298396 effective words) took 1.1s, 282468 effective words/s\n",
      "INFO - 20:55:02: EPOCH 18 - PROGRESS: at 90.48% examples, 268430 words/s, in_qsize 3, out_qsize 1\n",
      "INFO - 20:55:02: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:02: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:02: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:02: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:02: EPOCH - 18 : training on 298396 raw words (298396 effective words) took 1.0s, 293621 effective words/s\n",
      "INFO - 20:55:03: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:03: EPOCH 19 - PROGRESS: at 93.84% examples, 276883 words/s, in_qsize 0, out_qsize 5\n",
      "INFO - 20:55:03: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:03: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:03: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:03: EPOCH - 19 : training on 298396 raw words (298396 effective words) took 1.0s, 294587 effective words/s\n",
      "INFO - 20:55:04: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:04: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:04: EPOCH 20 - PROGRESS: at 97.19% examples, 288270 words/s, in_qsize 1, out_qsize 1\n",
      "INFO - 20:55:04: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:04: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:04: EPOCH - 20 : training on 298396 raw words (298396 effective words) took 1.0s, 294250 effective words/s\n",
      "INFO - 20:55:05: EPOCH 21 - PROGRESS: at 83.78% examples, 248293 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 20:55:05: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:05: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:05: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:05: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:05: EPOCH - 21 : training on 298396 raw words (298396 effective words) took 1.0s, 285050 effective words/s\n",
      "INFO - 20:55:06: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:06: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:06: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:06: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:06: EPOCH - 22 : training on 298396 raw words (298396 effective words) took 0.9s, 326349 effective words/s\n",
      "INFO - 20:55:07: EPOCH 23 - PROGRESS: at 90.48% examples, 269588 words/s, in_qsize 3, out_qsize 1\n",
      "INFO - 20:55:07: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:07: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:07: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:07: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:07: EPOCH - 23 : training on 298396 raw words (298396 effective words) took 1.0s, 290266 effective words/s\n",
      "INFO - 20:55:08: EPOCH 24 - PROGRESS: at 87.13% examples, 259487 words/s, in_qsize 4, out_qsize 0\n",
      "INFO - 20:55:08: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:08: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:08: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:08: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:08: EPOCH - 24 : training on 298396 raw words (298396 effective words) took 1.0s, 289425 effective words/s\n",
      "INFO - 20:55:09: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:09: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:09: EPOCH 25 - PROGRESS: at 97.19% examples, 289855 words/s, in_qsize 1, out_qsize 1\n",
      "INFO - 20:55:09: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:09: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:09: EPOCH - 25 : training on 298396 raw words (298396 effective words) took 1.0s, 294961 effective words/s\n",
      "INFO - 20:55:10: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:10: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:10: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:10: EPOCH 26 - PROGRESS: at 100.00% examples, 298388 words/s, in_qsize 0, out_qsize 1\n",
      "INFO - 20:55:10: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:10: EPOCH - 26 : training on 298396 raw words (298396 effective words) took 1.0s, 298099 effective words/s\n",
      "INFO - 20:55:11: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:11: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:11: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:11: EPOCH 27 - PROGRESS: at 100.00% examples, 297937 words/s, in_qsize 0, out_qsize 1\n",
      "INFO - 20:55:11: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:11: EPOCH - 27 : training on 298396 raw words (298396 effective words) took 1.0s, 297647 effective words/s\n",
      "INFO - 20:55:12: EPOCH 28 - PROGRESS: at 63.67% examples, 186159 words/s, in_qsize 6, out_qsize 1\n",
      "INFO - 20:55:13: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:13: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:13: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:13: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:13: EPOCH - 28 : training on 298396 raw words (298396 effective words) took 1.1s, 264634 effective words/s\n",
      "INFO - 20:55:14: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:14: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:14: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:14: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:14: EPOCH - 29 : training on 298396 raw words (298396 effective words) took 1.0s, 313280 effective words/s\n",
      "INFO - 20:55:15: EPOCH 30 - PROGRESS: at 90.48% examples, 267280 words/s, in_qsize 2, out_qsize 3\n",
      "INFO - 20:55:15: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:15: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:15: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:15: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:15: EPOCH - 30 : training on 298396 raw words (298396 effective words) took 1.0s, 292134 effective words/s\n",
      "INFO - 20:55:16: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:16: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:16: EPOCH 31 - PROGRESS: at 97.19% examples, 288469 words/s, in_qsize 1, out_qsize 1\n",
      "INFO - 20:55:16: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:16: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:16: EPOCH - 31 : training on 298396 raw words (298396 effective words) took 1.0s, 294800 effective words/s\n",
      "INFO - 20:55:17: EPOCH 32 - PROGRESS: at 73.73% examples, 213929 words/s, in_qsize 7, out_qsize 0\n",
      "INFO - 20:55:17: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:17: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:17: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:17: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:17: EPOCH - 32 : training on 298396 raw words (298396 effective words) took 1.1s, 271250 effective words/s\n",
      "INFO - 20:55:18: EPOCH 33 - PROGRESS: at 80.43% examples, 237935 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 20:55:18: worker thread finished; awaiting finish of 3 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 20:55:18: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:18: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:18: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:18: EPOCH - 33 : training on 298396 raw words (298396 effective words) took 1.1s, 283016 effective words/s\n",
      "INFO - 20:55:19: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:19: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:19: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:19: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:19: EPOCH - 34 : training on 298396 raw words (298396 effective words) took 1.0s, 302753 effective words/s\n",
      "INFO - 20:55:20: EPOCH 35 - PROGRESS: at 80.43% examples, 236249 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 20:55:20: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:20: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:20: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:20: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:20: EPOCH - 35 : training on 298396 raw words (298396 effective words) took 1.1s, 281043 effective words/s\n",
      "INFO - 20:55:21: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:21: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:21: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:21: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:21: EPOCH - 36 : training on 298396 raw words (298396 effective words) took 1.0s, 311782 effective words/s\n",
      "INFO - 20:55:22: EPOCH 37 - PROGRESS: at 67.03% examples, 196764 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 20:55:22: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:22: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:22: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:22: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:22: EPOCH - 37 : training on 298396 raw words (298396 effective words) took 1.1s, 270172 effective words/s\n",
      "INFO - 20:55:23: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:23: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:23: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:23: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:23: EPOCH - 38 : training on 298396 raw words (298396 effective words) took 0.9s, 318769 effective words/s\n",
      "INFO - 20:55:24: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:24: EPOCH 39 - PROGRESS: at 93.84% examples, 277144 words/s, in_qsize 2, out_qsize 1\n",
      "INFO - 20:55:24: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:24: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:24: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:24: EPOCH - 39 : training on 298396 raw words (298396 effective words) took 1.0s, 291589 effective words/s\n",
      "INFO - 20:55:25: EPOCH 40 - PROGRESS: at 80.43% examples, 238932 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 20:55:25: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:25: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:25: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:25: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:25: EPOCH - 40 : training on 298396 raw words (298396 effective words) took 1.1s, 283835 effective words/s\n",
      "INFO - 20:55:26: EPOCH 41 - PROGRESS: at 63.67% examples, 189792 words/s, in_qsize 7, out_qsize 0\n",
      "INFO - 20:55:26: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:26: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:26: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:26: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:26: EPOCH - 41 : training on 298396 raw words (298396 effective words) took 1.1s, 269501 effective words/s\n",
      "INFO - 20:55:27: EPOCH 42 - PROGRESS: at 83.78% examples, 246876 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 20:55:27: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:27: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:27: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:27: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:27: EPOCH - 42 : training on 298396 raw words (298396 effective words) took 1.0s, 284689 effective words/s\n",
      "INFO - 20:55:28: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:28: EPOCH 43 - PROGRESS: at 93.84% examples, 278506 words/s, in_qsize 2, out_qsize 1\n",
      "INFO - 20:55:28: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:28: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:28: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:28: EPOCH - 43 : training on 298396 raw words (298396 effective words) took 1.0s, 295077 effective words/s\n",
      "INFO - 20:55:29: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:29: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:29: EPOCH 44 - PROGRESS: at 96.65% examples, 287761 words/s, in_qsize 1, out_qsize 1\n",
      "INFO - 20:55:29: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:29: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:29: EPOCH - 44 : training on 298396 raw words (298396 effective words) took 1.0s, 296586 effective words/s\n",
      "INFO - 20:55:30: EPOCH 45 - PROGRESS: at 80.43% examples, 239174 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 20:55:30: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:30: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:30: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:30: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:30: EPOCH - 45 : training on 298396 raw words (298396 effective words) took 1.0s, 284550 effective words/s\n",
      "INFO - 20:55:31: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:31: EPOCH 46 - PROGRESS: at 93.84% examples, 276660 words/s, in_qsize 2, out_qsize 1\n",
      "INFO - 20:55:31: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:31: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:31: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:31: EPOCH - 46 : training on 298396 raw words (298396 effective words) took 1.0s, 289693 effective words/s\n",
      "INFO - 20:55:32: EPOCH 47 - PROGRESS: at 87.13% examples, 257145 words/s, in_qsize 3, out_qsize 2\n",
      "INFO - 20:55:32: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:32: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:32: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:32: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:32: EPOCH - 47 : training on 298396 raw words (298396 effective words) took 1.0s, 288463 effective words/s\n",
      "INFO - 20:55:33: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:33: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:33: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:33: EPOCH 48 - PROGRESS: at 100.00% examples, 297361 words/s, in_qsize 0, out_qsize 1\n",
      "INFO - 20:55:33: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:33: EPOCH - 48 : training on 298396 raw words (298396 effective words) took 1.0s, 297059 effective words/s\n",
      "INFO - 20:55:35: EPOCH 49 - PROGRESS: at 63.67% examples, 177902 words/s, in_qsize 7, out_qsize 0\n",
      "INFO - 20:55:35: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:35: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:35: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:35: worker thread finished; awaiting finish of 0 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 20:55:35: EPOCH - 49 : training on 298396 raw words (298396 effective words) took 1.2s, 257158 effective words/s\n",
      "INFO - 20:55:36: EPOCH 50 - PROGRESS: at 90.48% examples, 269118 words/s, in_qsize 2, out_qsize 3\n",
      "INFO - 20:55:36: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:36: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:36: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:36: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:36: EPOCH - 50 : training on 298396 raw words (298396 effective words) took 1.0s, 292388 effective words/s\n",
      "INFO - 20:55:37: EPOCH 51 - PROGRESS: at 90.48% examples, 269149 words/s, in_qsize 3, out_qsize 1\n",
      "INFO - 20:55:37: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:37: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:37: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:37: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:37: EPOCH - 51 : training on 298396 raw words (298396 effective words) took 1.0s, 289188 effective words/s\n",
      "INFO - 20:55:38: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:38: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:38: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:38: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:38: EPOCH - 52 : training on 298396 raw words (298396 effective words) took 1.0s, 302405 effective words/s\n",
      "INFO - 20:55:39: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:39: EPOCH 53 - PROGRESS: at 93.84% examples, 279791 words/s, in_qsize 2, out_qsize 1\n",
      "INFO - 20:55:39: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:39: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:39: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:39: EPOCH - 53 : training on 298396 raw words (298396 effective words) took 1.0s, 293050 effective words/s\n",
      "INFO - 20:55:40: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:40: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:40: EPOCH 54 - PROGRESS: at 97.19% examples, 288434 words/s, in_qsize 1, out_qsize 1\n",
      "INFO - 20:55:40: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:40: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:40: EPOCH - 54 : training on 298396 raw words (298396 effective words) took 1.0s, 296008 effective words/s\n",
      "INFO - 20:55:41: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:41: EPOCH 55 - PROGRESS: at 93.84% examples, 278333 words/s, in_qsize 2, out_qsize 1\n",
      "INFO - 20:55:41: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:41: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:41: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:41: EPOCH - 55 : training on 298396 raw words (298396 effective words) took 1.0s, 292235 effective words/s\n",
      "INFO - 20:55:42: EPOCH 56 - PROGRESS: at 77.08% examples, 227092 words/s, in_qsize 7, out_qsize 0\n",
      "INFO - 20:55:42: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:42: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:42: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:42: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:42: EPOCH - 56 : training on 298396 raw words (298396 effective words) took 1.1s, 277001 effective words/s\n",
      "INFO - 20:55:43: EPOCH 57 - PROGRESS: at 63.67% examples, 188339 words/s, in_qsize 6, out_qsize 1\n",
      "INFO - 20:55:43: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:43: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:43: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:43: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:43: EPOCH - 57 : training on 298396 raw words (298396 effective words) took 1.1s, 269977 effective words/s\n",
      "INFO - 20:55:44: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:44: EPOCH 58 - PROGRESS: at 93.84% examples, 278802 words/s, in_qsize 2, out_qsize 1\n",
      "INFO - 20:55:44: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:44: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:44: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:44: EPOCH - 58 : training on 298396 raw words (298396 effective words) took 1.0s, 293853 effective words/s\n",
      "INFO - 20:55:45: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:45: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:45: EPOCH 59 - PROGRESS: at 97.19% examples, 288456 words/s, in_qsize 1, out_qsize 1\n",
      "INFO - 20:55:45: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:45: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:45: EPOCH - 59 : training on 298396 raw words (298396 effective words) took 1.0s, 295159 effective words/s\n",
      "INFO - 20:55:46: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:46: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:46: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:46: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:46: EPOCH - 60 : training on 298396 raw words (298396 effective words) took 1.0s, 299772 effective words/s\n",
      "INFO - 20:55:47: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:47: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:47: EPOCH 61 - PROGRESS: at 97.19% examples, 284922 words/s, in_qsize 1, out_qsize 1\n",
      "INFO - 20:55:47: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:47: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:47: EPOCH - 61 : training on 298396 raw words (298396 effective words) took 1.0s, 291392 effective words/s\n",
      "INFO - 20:55:48: EPOCH 62 - PROGRESS: at 90.48% examples, 269048 words/s, in_qsize 3, out_qsize 1\n",
      "INFO - 20:55:48: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:48: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:48: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:48: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:48: EPOCH - 62 : training on 298396 raw words (298396 effective words) took 1.0s, 292812 effective words/s\n",
      "INFO - 20:55:49: EPOCH 63 - PROGRESS: at 90.48% examples, 266648 words/s, in_qsize 3, out_qsize 1\n",
      "INFO - 20:55:49: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:49: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:49: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:49: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:49: EPOCH - 63 : training on 298396 raw words (298396 effective words) took 1.0s, 289569 effective words/s\n",
      "INFO - 20:55:50: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:50: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:50: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:50: EPOCH 64 - PROGRESS: at 100.00% examples, 296477 words/s, in_qsize 0, out_qsize 1\n",
      "INFO - 20:55:50: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:50: EPOCH - 64 : training on 298396 raw words (298396 effective words) took 1.0s, 296217 effective words/s\n",
      "INFO - 20:55:51: EPOCH 65 - PROGRESS: at 70.38% examples, 203574 words/s, in_qsize 7, out_qsize 0\n",
      "INFO - 20:55:51: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:51: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:51: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:51: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:51: EPOCH - 65 : training on 298396 raw words (298396 effective words) took 1.1s, 269494 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 20:55:52: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:52: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:52: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:52: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:52: EPOCH - 66 : training on 298396 raw words (298396 effective words) took 1.0s, 298391 effective words/s\n",
      "INFO - 20:55:53: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:53: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:53: EPOCH 67 - PROGRESS: at 96.65% examples, 282878 words/s, in_qsize 1, out_qsize 1\n",
      "INFO - 20:55:53: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:53: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:53: EPOCH - 67 : training on 298396 raw words (298396 effective words) took 1.0s, 291246 effective words/s\n",
      "INFO - 20:55:54: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:54: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:54: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:54: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:54: EPOCH - 68 : training on 298396 raw words (298396 effective words) took 1.0s, 299316 effective words/s\n",
      "INFO - 20:55:55: EPOCH 69 - PROGRESS: at 70.38% examples, 209534 words/s, in_qsize 7, out_qsize 0\n",
      "INFO - 20:55:55: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:55: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:55: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:55: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:55: EPOCH - 69 : training on 298396 raw words (298396 effective words) took 1.1s, 273544 effective words/s\n",
      "INFO - 20:55:56: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:56: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:56: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:56: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:56: EPOCH - 70 : training on 298396 raw words (298396 effective words) took 0.9s, 316221 effective words/s\n",
      "INFO - 20:55:57: EPOCH 71 - PROGRESS: at 67.03% examples, 198633 words/s, in_qsize 7, out_qsize 0\n",
      "INFO - 20:55:58: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:58: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:58: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:58: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:58: EPOCH - 71 : training on 298396 raw words (298396 effective words) took 1.1s, 270235 effective words/s\n",
      "INFO - 20:55:59: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:55:59: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:55:59: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:55:59: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:55:59: EPOCH - 72 : training on 298396 raw words (298396 effective words) took 0.9s, 315896 effective words/s\n",
      "INFO - 20:56:00: EPOCH 73 - PROGRESS: at 63.67% examples, 188939 words/s, in_qsize 7, out_qsize 0\n",
      "INFO - 20:56:00: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:56:00: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:56:00: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:56:00: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:56:00: EPOCH - 73 : training on 298396 raw words (298396 effective words) took 1.1s, 270482 effective words/s\n",
      "INFO - 20:56:01: EPOCH 74 - PROGRESS: at 90.48% examples, 269814 words/s, in_qsize 3, out_qsize 1\n",
      "INFO - 20:56:01: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:56:01: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:56:01: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:56:01: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:56:01: EPOCH - 74 : training on 298396 raw words (298396 effective words) took 1.0s, 292510 effective words/s\n",
      "INFO - 20:56:02: EPOCH 75 - PROGRESS: at 63.67% examples, 188118 words/s, in_qsize 7, out_qsize 0\n",
      "INFO - 20:56:02: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:56:02: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:56:02: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:56:02: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:56:02: EPOCH - 75 : training on 298396 raw words (298396 effective words) took 1.1s, 269307 effective words/s\n",
      "INFO - 20:56:03: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:56:03: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:56:03: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:56:03: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:56:03: EPOCH - 76 : training on 298396 raw words (298396 effective words) took 0.9s, 316079 effective words/s\n",
      "INFO - 20:56:04: EPOCH 77 - PROGRESS: at 83.78% examples, 248424 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 20:56:04: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:56:04: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:56:04: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:56:04: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:56:04: EPOCH - 77 : training on 298396 raw words (298396 effective words) took 1.0s, 286761 effective words/s\n",
      "INFO - 20:56:05: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:56:05: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:56:05: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:56:05: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:56:05: EPOCH - 78 : training on 298396 raw words (298396 effective words) took 0.9s, 317926 effective words/s\n",
      "INFO - 20:56:06: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:56:06: EPOCH 79 - PROGRESS: at 93.84% examples, 276521 words/s, in_qsize 1, out_qsize 3\n",
      "INFO - 20:56:06: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:56:06: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:56:06: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:56:06: EPOCH - 79 : training on 298396 raw words (298396 effective words) took 1.0s, 293554 effective words/s\n",
      "INFO - 20:56:07: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:56:07: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:56:07: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:56:07: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:56:07: EPOCH - 80 : training on 298396 raw words (298396 effective words) took 1.0s, 298550 effective words/s\n",
      "INFO - 20:56:08: EPOCH 81 - PROGRESS: at 80.43% examples, 233096 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 20:56:08: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:56:08: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:56:08: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:56:08: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:56:08: EPOCH - 81 : training on 298396 raw words (298396 effective words) took 1.1s, 273640 effective words/s\n",
      "INFO - 20:56:09: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:56:09: EPOCH 82 - PROGRESS: at 93.84% examples, 277595 words/s, in_qsize 2, out_qsize 1\n",
      "INFO - 20:56:09: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:56:09: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:56:09: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:56:09: EPOCH - 82 : training on 298396 raw words (298396 effective words) took 1.0s, 294082 effective words/s\n",
      "INFO - 20:56:10: worker thread finished; awaiting finish of 3 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 20:56:10: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:56:10: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:56:10: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:56:10: EPOCH - 83 : training on 298396 raw words (298396 effective words) took 1.0s, 304359 effective words/s\n",
      "INFO - 20:56:11: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:56:11: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:56:11: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:56:11: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:56:11: EPOCH - 84 : training on 298396 raw words (298396 effective words) took 0.9s, 320650 effective words/s\n",
      "INFO - 20:56:12: EPOCH 85 - PROGRESS: at 90.48% examples, 269803 words/s, in_qsize 2, out_qsize 3\n",
      "INFO - 20:56:12: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:56:12: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:56:12: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:56:12: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:56:12: EPOCH - 85 : training on 298396 raw words (298396 effective words) took 1.0s, 291951 effective words/s\n",
      "INFO - 20:56:13: EPOCH 86 - PROGRESS: at 73.73% examples, 214519 words/s, in_qsize 7, out_qsize 0\n",
      "INFO - 20:56:13: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:56:13: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:56:13: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:56:13: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:56:13: EPOCH - 86 : training on 298396 raw words (298396 effective words) took 1.1s, 272068 effective words/s\n",
      "INFO - 20:56:14: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:56:14: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:56:14: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:56:14: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:56:14: EPOCH - 87 : training on 298396 raw words (298396 effective words) took 1.0s, 313909 effective words/s\n",
      "INFO - 20:56:15: EPOCH 88 - PROGRESS: at 90.48% examples, 269173 words/s, in_qsize 3, out_qsize 1\n",
      "INFO - 20:56:15: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:56:15: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:56:15: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:56:15: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:56:15: EPOCH - 88 : training on 298396 raw words (298396 effective words) took 1.0s, 288935 effective words/s\n",
      "INFO - 20:56:16: EPOCH 89 - PROGRESS: at 60.32% examples, 177157 words/s, in_qsize 7, out_qsize 0\n",
      "INFO - 20:56:16: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:56:16: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:56:16: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:56:16: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:56:16: EPOCH - 89 : training on 298396 raw words (298396 effective words) took 1.1s, 265799 effective words/s\n",
      "INFO - 20:56:17: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:56:17: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:56:17: EPOCH 90 - PROGRESS: at 96.65% examples, 287678 words/s, in_qsize 0, out_qsize 3\n",
      "INFO - 20:56:17: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:56:17: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:56:17: EPOCH - 90 : training on 298396 raw words (298396 effective words) took 1.0s, 297271 effective words/s\n",
      "INFO - 20:56:18: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:56:18: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:56:18: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:56:18: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:56:18: EPOCH - 91 : training on 298396 raw words (298396 effective words) took 1.0s, 299823 effective words/s\n",
      "INFO - 20:56:19: EPOCH 92 - PROGRESS: at 87.13% examples, 259667 words/s, in_qsize 4, out_qsize 0\n",
      "INFO - 20:56:19: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:56:19: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:56:19: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:56:19: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:56:19: EPOCH - 92 : training on 298396 raw words (298396 effective words) took 1.0s, 289891 effective words/s\n",
      "INFO - 20:56:20: EPOCH 93 - PROGRESS: at 67.03% examples, 196656 words/s, in_qsize 7, out_qsize 0\n",
      "INFO - 20:56:21: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:56:21: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:56:21: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:56:21: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:56:21: EPOCH - 93 : training on 298396 raw words (298396 effective words) took 1.1s, 268805 effective words/s\n",
      "INFO - 20:56:22: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:56:22: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:56:22: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:56:22: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:56:22: EPOCH - 94 : training on 298396 raw words (298396 effective words) took 1.0s, 307022 effective words/s\n",
      "INFO - 20:56:23: EPOCH 95 - PROGRESS: at 70.38% examples, 206535 words/s, in_qsize 7, out_qsize 0\n",
      "INFO - 20:56:23: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:56:23: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:56:23: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:56:23: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:56:23: EPOCH - 95 : training on 298396 raw words (298396 effective words) took 1.1s, 268739 effective words/s\n",
      "INFO - 20:56:24: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:56:24: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:56:24: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:56:24: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:56:24: EPOCH - 96 : training on 298396 raw words (298396 effective words) took 1.0s, 299040 effective words/s\n",
      "INFO - 20:56:25: EPOCH 97 - PROGRESS: at 60.32% examples, 171554 words/s, in_qsize 4, out_qsize 3\n",
      "INFO - 20:56:25: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:56:25: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:56:25: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:56:25: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:56:25: EPOCH - 97 : training on 298396 raw words (298396 effective words) took 1.2s, 256065 effective words/s\n",
      "INFO - 20:56:26: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:56:26: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:56:26: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:56:26: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:56:26: EPOCH - 98 : training on 298396 raw words (298396 effective words) took 1.0s, 300754 effective words/s\n",
      "INFO - 20:56:27: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 20:56:27: EPOCH 99 - PROGRESS: at 93.84% examples, 273341 words/s, in_qsize 2, out_qsize 1\n",
      "INFO - 20:56:27: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:56:27: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:56:27: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:56:27: EPOCH - 99 : training on 298396 raw words (298396 effective words) took 1.0s, 290231 effective words/s\n",
      "INFO - 20:56:28: EPOCH 100 - PROGRESS: at 87.13% examples, 251897 words/s, in_qsize 4, out_qsize 0\n",
      "INFO - 20:56:28: worker thread finished; awaiting finish of 3 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 20:56:28: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 20:56:28: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 20:56:28: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 20:56:28: EPOCH - 100 : training on 298396 raw words (298396 effective words) took 1.1s, 282321 effective words/s\n",
      "INFO - 20:56:28: Word2Vec lifecycle event {'msg': 'training on 29839600 raw words (29839600 effective words) took 104.9s, 284342 effective words/s', 'datetime': '2021-11-15T20:56:28.616240', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "INFO - 20:56:28: Word2Vec lifecycle event {'fname_or_handle': 'w2v.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2021-11-15T20:56:28.617242', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'saving'}\n",
      "INFO - 20:56:28: storing np array 'vectors' to w2v.model.wv.vectors.npy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 1.75 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 20:56:31: storing np array 'syn1neg' to w2v.model.syn1neg.npy\n",
      "INFO - 20:56:31: not storing attribute cum_table\n",
      "INFO - 20:56:31: saved w2v.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "\n",
    "t = time()\n",
    "model.train(bigram_sentences, total_examples=model.corpus_count, epochs=100)\n",
    "\n",
    "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))\n",
    "\n",
    "model.save(\"w2v.model\")\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9b4e7009",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('senior technical writer contract', 0.26377832889556885),\n",
       " ('technical support (contract)', 0.22593717277050018),\n",
       " ('president/independent consultant', 0.22013071179389954),\n",
       " ('sessional instructor', 0.21934692561626434),\n",
       " ('front desk coordinator/senior sourcer/ jr. recruiter', 0.21793535351753235),\n",
       " ('qa lead engineer  wafl', 0.217039555311203),\n",
       " ('manager - field sales', 0.21519960463047028),\n",
       " ('systems engineer summer intern', 0.21515102684497833),\n",
       " ('senior director  business operations & analytics', 0.21431227028369904),\n",
       " ('game designer  the godfather: the game', 0.2119659036397934)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# well let's see how we did\n",
    "\n",
    "model.wv.most_similar('software engineer', topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a874de75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.073169254"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('software engineer', 'engineer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080c869d",
   "metadata": {},
   "source": [
    "###### Well it seems like the result isn't what we were expecting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f4548e",
   "metadata": {},
   "source": [
    "###### --------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc6dab2",
   "metadata": {},
   "source": [
    "###### Using Doc2Vec to train a model on the same dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ee32a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f89286d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using Doc2Vec with df as the dataframe with lowercase csv read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "23db458e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "from collections import defaultdict\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "081de4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6d48ca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find current working directory\n",
    "directory = os.getcwd()\n",
    "\n",
    "# specifying csv filename, this is a switch between two datasets in the directory.\n",
    "\n",
    "# filename = \"\\\\job_title.csv\"\n",
    "filename = \"\\\\titles_final.csv\"\n",
    "\n",
    "# using concat to generate fullpath\n",
    "file = directory+filename\n",
    "\n",
    "# load csv file containing job titles\n",
    "df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1b1da388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc2vec tagging\n",
    "\n",
    "tagged_data = [TaggedDocument(words=word_tokenize(_d.lower(), preserve_line=True), tags=[str(i)]) for i, _d in enumerate(df[\"Titles\"])]\n",
    "\n",
    "# tagged_data = [TaggedDocument(words=word_tokenize(_d.lower(), preserve_line=True), tags=[str(i)]) for i, _d in enumerate(df[\"Titles\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b47cae76",
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_data_backup = tagged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "491397d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def listoflists(inputlist):\n",
    "#     return [[el] for el in inputlist]\n",
    "\n",
    "# nestedlist = listoflists(tagged_data)\n",
    "\n",
    "# # reinitializing the dataset again\n",
    "\n",
    "#  df = pd.DataFrame({'Titles':nestedlist})\n",
    "#  df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "7e981bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[TaggedDocument(words=['solutions', 'engineer'], tags=['1'])], [TaggedDocument(words=['staff', 'software', 'engineer'], tags=['2'])], [TaggedDocument(words=['head', 'of', 'product', '(', 'platform', ')'], tags=['3'])], [TaggedDocument(words=['incubation', 'lead', 'success', 'cloud'], tags=['4'])], [TaggedDocument(words=['author'], tags=['5'])], [TaggedDocument(words=['technical', 'writer'], tags=['6'])], [TaggedDocument(words=['product'], tags=['7'])], [TaggedDocument(words=['technology', 'architecture', 'and', 'operations'], tags=['8'])], [TaggedDocument(words=['software', 'engineer'], tags=['9'])]]\n",
      "---------------\n",
      "[TaggedDocument(words=['solutions', 'engineer'], tags=['1']), TaggedDocument(words=['staff', 'software', 'engineer'], tags=['2']), TaggedDocument(words=['head', 'of', 'product', '(', 'platform', ')'], tags=['3']), TaggedDocument(words=['incubation', 'lead', 'success', 'cloud'], tags=['4']), TaggedDocument(words=['author'], tags=['5']), TaggedDocument(words=['technical', 'writer'], tags=['6']), TaggedDocument(words=['product'], tags=['7']), TaggedDocument(words=['technology', 'architecture', 'and', 'operations'], tags=['8']), TaggedDocument(words=['software', 'engineer'], tags=['9'])]\n"
     ]
    }
   ],
   "source": [
    "print(nestedlist[1:10])\n",
    "print(\"---------------\")\n",
    "print(tagged_data_backup[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "07b8b299",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 21:58:58: Doc2Vec lifecycle event {'params': 'Doc2Vec(dm/m,d100,n5,w5,s0.001,t3)', 'datetime': '2021-11-15T21:58:58.174503', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n",
      "INFO - 21:58:58: collecting all words and their counts\n",
      "INFO - 21:58:58: PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "INFO - 21:58:58: PROGRESS: at example #10000, processed 41471 words (613440/s), 2366 word types, 10000 tags\n",
      "INFO - 21:58:58: PROGRESS: at example #20000, processed 80563 words (1981539/s), 3561 word types, 20000 tags\n",
      "INFO - 21:58:58: PROGRESS: at example #30000, processed 117636 words (1713661/s), 4528 word types, 30000 tags\n",
      "INFO - 21:58:58: PROGRESS: at example #40000, processed 152103 words (1587806/s), 5256 word types, 40000 tags\n",
      "INFO - 21:58:58: PROGRESS: at example #50000, processed 184287 words (1415459/s), 5934 word types, 50000 tags\n",
      "INFO - 21:58:58: PROGRESS: at example #60000, processed 223647 words (1752620/s), 6861 word types, 60000 tags\n",
      "INFO - 21:58:58: PROGRESS: at example #70000, processed 262238 words (1897156/s), 7759 word types, 70000 tags\n",
      "INFO - 21:58:58: PROGRESS: at example #80000, processed 299113 words (1708037/s), 8595 word types, 80000 tags\n",
      "INFO - 21:58:58: PROGRESS: at example #90000, processed 333826 words (1553494/s), 9323 word types, 90000 tags\n",
      "INFO - 21:58:58: PROGRESS: at example #100000, processed 366833 words (1699035/s), 10044 word types, 100000 tags\n",
      "INFO - 21:58:58: PROGRESS: at example #110000, processed 403879 words (1774216/s), 10780 word types, 110000 tags\n",
      "INFO - 21:58:58: PROGRESS: at example #120000, processed 441638 words (1704033/s), 11499 word types, 120000 tags\n",
      "INFO - 21:58:58: PROGRESS: at example #130000, processed 477929 words (1631657/s), 12216 word types, 130000 tags\n",
      "INFO - 21:58:58: PROGRESS: at example #140000, processed 511714 words (1583956/s), 12846 word types, 140000 tags\n",
      "INFO - 21:58:58: PROGRESS: at example #150000, processed 544395 words (1522979/s), 13560 word types, 150000 tags\n",
      "INFO - 21:58:58: PROGRESS: at example #160000, processed 580323 words (1688544/s), 14183 word types, 160000 tags\n",
      "INFO - 21:58:58: PROGRESS: at example #170000, processed 616366 words (1598493/s), 14865 word types, 170000 tags\n",
      "INFO - 21:58:58: PROGRESS: at example #180000, processed 650517 words (1191857/s), 15499 word types, 180000 tags\n",
      "INFO - 21:58:58: PROGRESS: at example #190000, processed 682997 words (1490968/s), 16230 word types, 190000 tags\n",
      "INFO - 21:58:58: PROGRESS: at example #200000, processed 717046 words (1600754/s), 16874 word types, 200000 tags\n",
      "INFO - 21:58:58: PROGRESS: at example #210000, processed 751776 words (1593982/s), 17493 word types, 210000 tags\n",
      "INFO - 21:58:58: PROGRESS: at example #220000, processed 784036 words (1533277/s), 18209 word types, 220000 tags\n",
      "INFO - 21:58:58: PROGRESS: at example #230000, processed 817405 words (1617632/s), 18882 word types, 230000 tags\n",
      "INFO - 21:58:58: PROGRESS: at example #240000, processed 850519 words (1517341/s), 19535 word types, 240000 tags\n",
      "INFO - 21:58:59: PROGRESS: at example #250000, processed 882610 words (1567655/s), 20262 word types, 250000 tags\n",
      "INFO - 21:58:59: PROGRESS: at example #260000, processed 915444 words (1590247/s), 20957 word types, 260000 tags\n",
      "INFO - 21:58:59: PROGRESS: at example #270000, processed 947667 words (1478804/s), 21651 word types, 270000 tags\n",
      "INFO - 21:58:59: PROGRESS: at example #280000, processed 979493 words (1202819/s), 22315 word types, 280000 tags\n",
      "INFO - 21:58:59: PROGRESS: at example #290000, processed 1011171 words (1311495/s), 23100 word types, 290000 tags\n",
      "INFO - 21:59:00: collected 23820 word types and 298396 unique tags from a corpus of 298396 examples and 1037922 words\n",
      "INFO - 21:59:00: Creating a fresh vocabulary\n",
      "INFO - 21:59:00: Doc2Vec lifecycle event {'msg': 'effective_min_count=1 retains 23820 unique words (100.0%% of original 23820, drops 0)', 'datetime': '2021-11-15T21:59:00.948962', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "INFO - 21:59:00: Doc2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 1037922 word corpus (100.0%% of original 1037922, drops 0)', 'datetime': '2021-11-15T21:59:00.948962', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "INFO - 21:59:01: deleting the raw counts dictionary of 23820 items\n",
      "INFO - 21:59:01: sample=0.001 downsamples 63 most-common words\n",
      "INFO - 21:59:01: Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 589414.8631435008 word corpus (56.8%% of prior 1037922)', 'datetime': '2021-11-15T21:59:01.075960', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "INFO - 21:59:01: estimated required memory for 23820 words and 100 dimensions: 210003600 bytes\n",
      "INFO - 21:59:01: resetting layer weights\n",
      "INFO - 21:59:01: Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 23820 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5', 'datetime': '2021-11-15T21:59:01.446969', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 21:59:02: EPOCH 1 - PROGRESS: at 7.50% examples, 71525 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:59:03: EPOCH 1 - PROGRESS: at 14.21% examples, 61972 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:59:04: EPOCH 1 - PROGRESS: at 22.39% examples, 65696 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:59:05: EPOCH 1 - PROGRESS: at 30.77% examples, 66812 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:59:06: EPOCH 1 - PROGRESS: at 39.14% examples, 68301 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:59:07: EPOCH 1 - PROGRESS: at 47.75% examples, 68909 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:59:08: EPOCH 1 - PROGRESS: at 54.51% examples, 67618 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:59:09: EPOCH 1 - PROGRESS: at 63.34% examples, 67781 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:59:10: EPOCH 1 - PROGRESS: at 72.22% examples, 68346 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:59:11: EPOCH 1 - PROGRESS: at 80.36% examples, 68231 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:59:13: EPOCH 1 - PROGRESS: at 88.66% examples, 68425 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:59:14: EPOCH 1 - PROGRESS: at 97.04% examples, 68679 words/s, in_qsize 3, out_qsize 0\n",
      "INFO - 21:59:14: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 21:59:14: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 21:59:14: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 21:59:14: EPOCH - 1 : training on 1037922 raw words (888273 effective words) took 12.8s, 69218 effective words/s\n",
      "INFO - 21:59:15: EPOCH 2 - PROGRESS: at 8.40% examples, 61332 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:59:16: EPOCH 2 - PROGRESS: at 17.36% examples, 64234 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:59:17: EPOCH 2 - PROGRESS: at 25.03% examples, 66842 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:59:18: EPOCH 2 - PROGRESS: at 33.82% examples, 67386 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 21:59:19: EPOCH 2 - PROGRESS: at 41.88% examples, 68534 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:59:20: EPOCH 2 - PROGRESS: at 50.84% examples, 68440 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:59:22: EPOCH 2 - PROGRESS: at 59.24% examples, 68709 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:59:23: EPOCH 2 - PROGRESS: at 68.24% examples, 68679 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:59:24: EPOCH 2 - PROGRESS: at 77.31% examples, 68563 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:59:25: EPOCH 2 - PROGRESS: at 86.54% examples, 68662 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:59:26: EPOCH 2 - PROGRESS: at 94.94% examples, 68733 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:59:27: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 21:59:27: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 21:59:27: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 21:59:27: EPOCH - 2 : training on 1037922 raw words (888189 effective words) took 12.7s, 69722 effective words/s\n",
      "INFO - 21:59:28: EPOCH 3 - PROGRESS: at 8.42% examples, 61311 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:59:29: EPOCH 3 - PROGRESS: at 17.36% examples, 64611 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:59:30: EPOCH 3 - PROGRESS: at 25.95% examples, 67419 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:59:31: EPOCH 3 - PROGRESS: at 34.64% examples, 67270 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:59:32: EPOCH 3 - PROGRESS: at 42.80% examples, 67824 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:59:33: EPOCH 3 - PROGRESS: at 51.72% examples, 67800 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 21:59:34: EPOCH 3 - PROGRESS: at 60.26% examples, 68461 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:59:36: EPOCH 3 - PROGRESS: at 69.21% examples, 69141 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:59:37: EPOCH 3 - PROGRESS: at 77.31% examples, 69054 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:59:38: EPOCH 3 - PROGRESS: at 85.51% examples, 68616 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:59:39: EPOCH 3 - PROGRESS: at 94.94% examples, 68651 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:59:39: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 21:59:39: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 21:59:39: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 21:59:39: EPOCH - 3 : training on 1037922 raw words (887819 effective words) took 12.7s, 69641 effective words/s\n",
      "INFO - 21:59:41: EPOCH 4 - PROGRESS: at 8.40% examples, 62446 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:59:42: EPOCH 4 - PROGRESS: at 17.36% examples, 65460 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:59:43: EPOCH 4 - PROGRESS: at 25.95% examples, 67919 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:59:44: EPOCH 4 - PROGRESS: at 34.86% examples, 67349 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:59:45: EPOCH 4 - PROGRESS: at 42.80% examples, 67892 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 21:59:46: EPOCH 4 - PROGRESS: at 51.82% examples, 68009 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 21:59:47: EPOCH 4 - PROGRESS: at 60.26% examples, 68089 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:59:48: EPOCH 4 - PROGRESS: at 69.21% examples, 68432 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:59:50: EPOCH 4 - PROGRESS: at 78.32% examples, 68240 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:59:51: EPOCH 4 - PROGRESS: at 87.62% examples, 68102 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:59:52: EPOCH 4 - PROGRESS: at 97.04% examples, 68088 words/s, in_qsize 3, out_qsize 0\n",
      "INFO - 21:59:52: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 21:59:52: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 21:59:52: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 21:59:52: EPOCH - 4 : training on 1037922 raw words (887669 effective words) took 12.8s, 69192 effective words/s\n",
      "INFO - 21:59:53: EPOCH 5 - PROGRESS: at 8.40% examples, 60805 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:59:55: EPOCH 5 - PROGRESS: at 17.36% examples, 64200 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:59:56: EPOCH 5 - PROGRESS: at 25.95% examples, 67783 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:59:57: EPOCH 5 - PROGRESS: at 34.86% examples, 67802 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:59:58: EPOCH 5 - PROGRESS: at 42.80% examples, 68659 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 21:59:59: EPOCH 5 - PROGRESS: at 51.82% examples, 68833 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:00: EPOCH 5 - PROGRESS: at 60.26% examples, 68631 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:01: EPOCH 5 - PROGRESS: at 68.24% examples, 68822 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:02: EPOCH 5 - PROGRESS: at 75.37% examples, 68211 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:03: EPOCH 5 - PROGRESS: at 84.50% examples, 68099 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:04: EPOCH 5 - PROGRESS: at 92.83% examples, 68424 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:05: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 22:00:05: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 22:00:05: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:00:05: EPOCH - 5 : training on 1037922 raw words (887998 effective words) took 12.9s, 69021 effective words/s\n",
      "INFO - 22:00:06: EPOCH 6 - PROGRESS: at 8.40% examples, 61736 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:07: EPOCH 6 - PROGRESS: at 17.36% examples, 63459 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:00:09: EPOCH 6 - PROGRESS: at 25.03% examples, 65757 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:10: EPOCH 6 - PROGRESS: at 33.82% examples, 65699 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:11: EPOCH 6 - PROGRESS: at 41.88% examples, 66897 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:12: EPOCH 6 - PROGRESS: at 50.84% examples, 66288 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:13: EPOCH 6 - PROGRESS: at 59.24% examples, 66849 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:00:14: EPOCH 6 - PROGRESS: at 68.24% examples, 67087 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:15: EPOCH 6 - PROGRESS: at 77.31% examples, 67195 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:16: EPOCH 6 - PROGRESS: at 86.54% examples, 67439 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:18: EPOCH 6 - PROGRESS: at 94.94% examples, 67590 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:18: worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 22:00:18: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 22:00:18: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:00:18: EPOCH - 6 : training on 1037922 raw words (888979 effective words) took 13.0s, 68545 effective words/s\n",
      "INFO - 22:00:19: EPOCH 7 - PROGRESS: at 8.40% examples, 63824 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:20: EPOCH 7 - PROGRESS: at 17.36% examples, 65173 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:21: EPOCH 7 - PROGRESS: at 25.95% examples, 68028 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:23: EPOCH 7 - PROGRESS: at 34.86% examples, 67895 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:24: EPOCH 7 - PROGRESS: at 42.80% examples, 68483 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:25: EPOCH 7 - PROGRESS: at 51.82% examples, 68481 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:26: EPOCH 7 - PROGRESS: at 60.26% examples, 68645 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:27: EPOCH 7 - PROGRESS: at 68.24% examples, 68432 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:28: EPOCH 7 - PROGRESS: at 77.31% examples, 68241 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:29: EPOCH 7 - PROGRESS: at 86.54% examples, 68854 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:30: EPOCH 7 - PROGRESS: at 93.87% examples, 68090 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:00:31: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 22:00:31: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 22:00:31: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:00:31: EPOCH - 7 : training on 1037922 raw words (888284 effective words) took 12.8s, 69661 effective words/s\n",
      "INFO - 22:00:32: EPOCH 8 - PROGRESS: at 8.42% examples, 61362 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:33: EPOCH 8 - PROGRESS: at 17.09% examples, 64067 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:34: EPOCH 8 - PROGRESS: at 25.03% examples, 66636 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:35: EPOCH 8 - PROGRESS: at 33.82% examples, 67058 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:36: EPOCH 8 - PROGRESS: at 41.88% examples, 68080 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:37: EPOCH 8 - PROGRESS: at 50.84% examples, 68296 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:39: EPOCH 8 - PROGRESS: at 59.24% examples, 68497 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:40: EPOCH 8 - PROGRESS: at 68.24% examples, 68503 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:41: EPOCH 8 - PROGRESS: at 77.31% examples, 68387 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:42: EPOCH 8 - PROGRESS: at 85.51% examples, 68171 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:43: EPOCH 8 - PROGRESS: at 94.94% examples, 68239 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:44: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 22:00:44: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 22:00:44: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:00:44: EPOCH - 8 : training on 1037922 raw words (887642 effective words) took 12.8s, 69372 effective words/s\n",
      "INFO - 22:00:45: EPOCH 9 - PROGRESS: at 8.40% examples, 61924 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:46: EPOCH 9 - PROGRESS: at 17.09% examples, 64518 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:47: EPOCH 9 - PROGRESS: at 25.95% examples, 68753 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:48: EPOCH 9 - PROGRESS: at 33.82% examples, 67781 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:49: EPOCH 9 - PROGRESS: at 41.88% examples, 68853 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:50: EPOCH 9 - PROGRESS: at 50.84% examples, 68810 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:51: EPOCH 9 - PROGRESS: at 59.24% examples, 69149 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:00:52: EPOCH 9 - PROGRESS: at 67.29% examples, 69099 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:00:53: EPOCH 9 - PROGRESS: at 75.37% examples, 69173 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:54: EPOCH 9 - PROGRESS: at 83.52% examples, 68727 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:56: EPOCH 9 - PROGRESS: at 91.75% examples, 68346 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:00:56: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 22:00:56: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 22:00:56: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:00:56: EPOCH - 9 : training on 1037922 raw words (887761 effective words) took 12.7s, 69686 effective words/s\n",
      "INFO - 22:00:58: EPOCH 10 - PROGRESS: at 8.40% examples, 61613 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:00:59: EPOCH 10 - PROGRESS: at 17.09% examples, 63900 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:01:00: EPOCH 10 - PROGRESS: at 25.95% examples, 68246 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:01:01: EPOCH 10 - PROGRESS: at 33.82% examples, 67666 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:01:02: EPOCH 10 - PROGRESS: at 41.88% examples, 68489 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:01:03: EPOCH 10 - PROGRESS: at 50.84% examples, 68274 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:01:04: EPOCH 10 - PROGRESS: at 59.24% examples, 68346 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:01:05: EPOCH 10 - PROGRESS: at 68.24% examples, 68224 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:01:06: EPOCH 10 - PROGRESS: at 77.31% examples, 68188 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:01:08: EPOCH 10 - PROGRESS: at 86.54% examples, 68302 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:01:09: EPOCH 10 - PROGRESS: at 95.97% examples, 68575 words/s, in_qsize 4, out_qsize 0\n",
      "INFO - 22:01:09: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 22:01:09: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 22:01:09: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:01:09: EPOCH - 10 : training on 1037922 raw words (887663 effective words) took 12.7s, 69630 effective words/s\n",
      "INFO - 22:01:09: Doc2Vec lifecycle event {'msg': 'training on 10379220 raw words (8880277 effective words) took 128.2s, 69275 effective words/s', 'datetime': '2021-11-15T22:01:09.635560', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "WARNING - 22:01:09: Effective 'alpha' higher than previous training cycles\n",
      "INFO - 22:01:09: Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 23820 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5', 'datetime': '2021-11-15T22:01:09.636561', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 22:01:10: EPOCH 1 - PROGRESS: at 8.42% examples, 61118 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:01:12: EPOCH 1 - PROGRESS: at 17.12% examples, 63849 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:01:13: EPOCH 1 - PROGRESS: at 25.95% examples, 68821 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:01:14: EPOCH 1 - PROGRESS: at 33.82% examples, 67311 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:01:15: EPOCH 1 - PROGRESS: at 41.88% examples, 68449 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:01:16: EPOCH 1 - PROGRESS: at 50.84% examples, 68366 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:01:17: EPOCH 1 - PROGRESS: at 59.24% examples, 68588 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:01:18: EPOCH 1 - PROGRESS: at 68.24% examples, 68580 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:01:19: EPOCH 1 - PROGRESS: at 77.31% examples, 68595 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:01:20: EPOCH 1 - PROGRESS: at 85.51% examples, 68230 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:01:21: EPOCH 1 - PROGRESS: at 94.90% examples, 68322 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:01:22: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 22:01:22: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 22:01:22: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:01:22: EPOCH - 1 : training on 1037922 raw words (887525 effective words) took 12.7s, 69721 effective words/s\n",
      "INFO - 22:01:23: EPOCH 2 - PROGRESS: at 8.40% examples, 61218 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:01:24: EPOCH 2 - PROGRESS: at 17.36% examples, 63955 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:01:25: EPOCH 2 - PROGRESS: at 25.03% examples, 66595 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:01:26: EPOCH 2 - PROGRESS: at 33.82% examples, 66801 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:01:27: EPOCH 2 - PROGRESS: at 41.88% examples, 67911 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:01:29: EPOCH 2 - PROGRESS: at 50.84% examples, 68013 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:01:30: EPOCH 2 - PROGRESS: at 59.24% examples, 68208 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:01:31: EPOCH 2 - PROGRESS: at 68.24% examples, 68613 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:01:32: EPOCH 2 - PROGRESS: at 77.31% examples, 68504 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:01:33: EPOCH 2 - PROGRESS: at 86.54% examples, 68629 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:01:34: EPOCH 2 - PROGRESS: at 94.94% examples, 68920 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:01:35: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 22:01:35: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 22:01:35: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:01:35: EPOCH - 2 : training on 1037922 raw words (887362 effective words) took 12.7s, 69763 effective words/s\n",
      "INFO - 22:01:36: EPOCH 3 - PROGRESS: at 8.40% examples, 61118 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:01:37: EPOCH 3 - PROGRESS: at 17.12% examples, 63624 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:01:38: EPOCH 3 - PROGRESS: at 25.95% examples, 68166 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:01:39: EPOCH 3 - PROGRESS: at 33.82% examples, 67483 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:01:40: EPOCH 3 - PROGRESS: at 41.88% examples, 68571 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:01:41: EPOCH 3 - PROGRESS: at 49.81% examples, 68341 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:01:42: EPOCH 3 - PROGRESS: at 58.26% examples, 68396 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:01:43: EPOCH 3 - PROGRESS: at 67.29% examples, 68472 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:01:44: EPOCH 3 - PROGRESS: at 76.34% examples, 68974 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:01:46: EPOCH 3 - PROGRESS: at 84.50% examples, 69088 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:01:47: EPOCH 3 - PROGRESS: at 92.82% examples, 68588 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:01:47: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 22:01:47: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 22:01:47: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:01:47: EPOCH - 3 : training on 1037922 raw words (887878 effective words) took 12.7s, 69775 effective words/s\n",
      "INFO - 22:01:49: EPOCH 4 - PROGRESS: at 8.40% examples, 62924 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:01:50: EPOCH 4 - PROGRESS: at 17.36% examples, 64503 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:01:51: EPOCH 4 - PROGRESS: at 25.03% examples, 67055 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:01:52: EPOCH 4 - PROGRESS: at 33.82% examples, 67372 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:01:53: EPOCH 4 - PROGRESS: at 41.88% examples, 68391 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:01:54: EPOCH 4 - PROGRESS: at 50.84% examples, 68429 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:01:55: EPOCH 4 - PROGRESS: at 59.24% examples, 68704 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:01:56: EPOCH 4 - PROGRESS: at 68.24% examples, 68636 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:01:57: EPOCH 4 - PROGRESS: at 77.31% examples, 68598 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:01:59: EPOCH 4 - PROGRESS: at 86.54% examples, 68778 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:02:00: EPOCH 4 - PROGRESS: at 94.94% examples, 68704 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:02:00: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 22:02:00: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 22:02:00: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:02:00: EPOCH - 4 : training on 1037922 raw words (888178 effective words) took 12.7s, 69697 effective words/s\n",
      "INFO - 22:02:01: EPOCH 5 - PROGRESS: at 8.40% examples, 62751 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:02:02: EPOCH 5 - PROGRESS: at 17.36% examples, 65822 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:02:04: EPOCH 5 - PROGRESS: at 25.95% examples, 69275 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:02:05: EPOCH 5 - PROGRESS: at 33.82% examples, 68590 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:02:06: EPOCH 5 - PROGRESS: at 41.87% examples, 68913 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:02:07: EPOCH 5 - PROGRESS: at 50.84% examples, 69278 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:02:08: EPOCH 5 - PROGRESS: at 59.24% examples, 69811 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:02:09: EPOCH 5 - PROGRESS: at 67.29% examples, 69099 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:02:10: EPOCH 5 - PROGRESS: at 76.34% examples, 69637 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:02:11: EPOCH 5 - PROGRESS: at 83.50% examples, 68831 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:02:12: EPOCH 5 - PROGRESS: at 92.83% examples, 68868 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:02:13: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 22:02:13: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 22:02:13: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:02:13: EPOCH - 5 : training on 1037922 raw words (887375 effective words) took 12.7s, 69892 effective words/s\n",
      "INFO - 22:02:14: EPOCH 6 - PROGRESS: at 7.50% examples, 71832 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:02:15: EPOCH 6 - PROGRESS: at 14.21% examples, 62942 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:02:16: EPOCH 6 - PROGRESS: at 22.39% examples, 66391 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:02:17: EPOCH 6 - PROGRESS: at 30.77% examples, 66296 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:02:18: EPOCH 6 - PROGRESS: at 39.14% examples, 67388 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:02:19: EPOCH 6 - PROGRESS: at 47.75% examples, 67230 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:02:20: EPOCH 6 - PROGRESS: at 56.36% examples, 67634 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:02:21: EPOCH 6 - PROGRESS: at 65.30% examples, 67737 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:02:23: EPOCH 6 - PROGRESS: at 74.35% examples, 67741 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:02:24: EPOCH 6 - PROGRESS: at 82.52% examples, 67873 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:02:25: EPOCH 6 - PROGRESS: at 90.71% examples, 68138 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:02:26: EPOCH 6 - PROGRESS: at 98.09% examples, 67616 words/s, in_qsize 2, out_qsize 1\n",
      "INFO - 22:02:26: worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 22:02:26: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 22:02:26: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:02:26: EPOCH - 6 : training on 1037922 raw words (887846 effective words) took 12.9s, 68812 effective words/s\n",
      "INFO - 22:02:27: EPOCH 7 - PROGRESS: at 8.40% examples, 62978 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:02:28: EPOCH 7 - PROGRESS: at 17.36% examples, 65539 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:02:29: EPOCH 7 - PROGRESS: at 25.95% examples, 69588 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:02:30: EPOCH 7 - PROGRESS: at 33.82% examples, 67948 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:02:31: EPOCH 7 - PROGRESS: at 42.80% examples, 70320 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:02:32: EPOCH 7 - PROGRESS: at 49.81% examples, 67731 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:02:33: EPOCH 7 - PROGRESS: at 58.26% examples, 68242 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:02:35: EPOCH 7 - PROGRESS: at 67.31% examples, 68232 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:02:36: EPOCH 7 - PROGRESS: at 76.34% examples, 68649 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:02:37: EPOCH 7 - PROGRESS: at 85.51% examples, 68658 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:02:38: EPOCH 7 - PROGRESS: at 93.87% examples, 68587 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:02:38: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 22:02:38: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 22:02:39: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:02:39: EPOCH - 7 : training on 1037922 raw words (887616 effective words) took 12.7s, 69627 effective words/s\n",
      "INFO - 22:02:40: EPOCH 8 - PROGRESS: at 8.47% examples, 60593 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:02:41: EPOCH 8 - PROGRESS: at 17.09% examples, 63574 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:02:42: EPOCH 8 - PROGRESS: at 25.03% examples, 66202 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:02:43: EPOCH 8 - PROGRESS: at 33.82% examples, 66639 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:02:44: EPOCH 8 - PROGRESS: at 41.87% examples, 67615 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:02:45: EPOCH 8 - PROGRESS: at 50.84% examples, 68224 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:02:46: EPOCH 8 - PROGRESS: at 59.24% examples, 68802 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:02:47: EPOCH 8 - PROGRESS: at 68.24% examples, 69186 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:02:48: EPOCH 8 - PROGRESS: at 75.37% examples, 68127 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:02:50: EPOCH 8 - PROGRESS: at 84.50% examples, 68339 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:02:51: EPOCH 8 - PROGRESS: at 93.87% examples, 68733 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:02:51: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 22:02:51: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 22:02:51: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:02:51: EPOCH - 8 : training on 1037922 raw words (888143 effective words) took 12.8s, 69444 effective words/s\n",
      "INFO - 22:02:53: EPOCH 9 - PROGRESS: at 8.40% examples, 60730 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:02:54: EPOCH 9 - PROGRESS: at 17.36% examples, 63788 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:02:55: EPOCH 9 - PROGRESS: at 25.03% examples, 66616 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:02:56: EPOCH 9 - PROGRESS: at 33.82% examples, 67309 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:02:57: EPOCH 9 - PROGRESS: at 41.88% examples, 68505 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:02:58: EPOCH 9 - PROGRESS: at 50.84% examples, 68305 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:02:59: EPOCH 9 - PROGRESS: at 59.24% examples, 68335 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:03:00: EPOCH 9 - PROGRESS: at 68.27% examples, 68229 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:03:01: EPOCH 9 - PROGRESS: at 77.31% examples, 68494 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:03:02: EPOCH 9 - PROGRESS: at 86.54% examples, 68827 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:03:04: EPOCH 9 - PROGRESS: at 94.90% examples, 68320 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:03:04: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 22:03:04: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 22:03:04: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:03:04: EPOCH - 9 : training on 1037922 raw words (888013 effective words) took 12.7s, 69794 effective words/s\n",
      "INFO - 22:03:05: EPOCH 10 - PROGRESS: at 8.47% examples, 60948 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:03:06: EPOCH 10 - PROGRESS: at 17.09% examples, 63838 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:03:07: EPOCH 10 - PROGRESS: at 25.03% examples, 66480 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:03:09: EPOCH 10 - PROGRESS: at 33.82% examples, 66922 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:03:10: EPOCH 10 - PROGRESS: at 41.88% examples, 67959 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:03:11: EPOCH 10 - PROGRESS: at 50.84% examples, 68077 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:03:12: EPOCH 10 - PROGRESS: at 59.24% examples, 68363 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:03:13: EPOCH 10 - PROGRESS: at 68.24% examples, 68439 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:03:14: EPOCH 10 - PROGRESS: at 77.31% examples, 68365 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:03:15: EPOCH 10 - PROGRESS: at 86.54% examples, 68548 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:03:16: EPOCH 10 - PROGRESS: at 95.97% examples, 68905 words/s, in_qsize 4, out_qsize 0\n",
      "INFO - 22:03:17: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 22:03:17: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 22:03:17: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:03:17: EPOCH - 10 : training on 1037922 raw words (888118 effective words) took 12.7s, 69864 effective words/s\n",
      "INFO - 22:03:17: Doc2Vec lifecycle event {'msg': 'training on 10379220 raw words (8878054 effective words) took 127.6s, 69561 effective words/s', 'datetime': '2021-11-15T22:03:17.267581', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "INFO - 22:03:17: Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 23820 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5', 'datetime': '2021-11-15T22:03:17.267581', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 22:03:18: EPOCH 1 - PROGRESS: at 8.42% examples, 61184 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:03:19: EPOCH 1 - PROGRESS: at 17.36% examples, 64687 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:03:20: EPOCH 1 - PROGRESS: at 25.95% examples, 68462 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:03:21: EPOCH 1 - PROGRESS: at 34.86% examples, 67566 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:03:22: EPOCH 1 - PROGRESS: at 42.84% examples, 67824 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:03:24: EPOCH 1 - PROGRESS: at 51.72% examples, 68004 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:03:25: EPOCH 1 - PROGRESS: at 60.26% examples, 68371 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:03:26: EPOCH 1 - PROGRESS: at 69.21% examples, 68633 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:03:27: EPOCH 1 - PROGRESS: at 77.31% examples, 68493 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:03:28: EPOCH 1 - PROGRESS: at 86.54% examples, 68215 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:03:29: EPOCH 1 - PROGRESS: at 95.97% examples, 68585 words/s, in_qsize 4, out_qsize 0\n",
      "INFO - 22:03:29: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 22:03:30: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 22:03:30: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:03:30: EPOCH - 1 : training on 1037922 raw words (888083 effective words) took 12.8s, 69561 effective words/s\n",
      "INFO - 22:03:31: EPOCH 2 - PROGRESS: at 8.42% examples, 61643 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:03:32: EPOCH 2 - PROGRESS: at 17.36% examples, 64443 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:03:33: EPOCH 2 - PROGRESS: at 25.03% examples, 66946 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:03:34: EPOCH 2 - PROGRESS: at 33.82% examples, 67355 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:03:35: EPOCH 2 - PROGRESS: at 41.88% examples, 68084 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:03:36: EPOCH 2 - PROGRESS: at 50.84% examples, 68831 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:03:37: EPOCH 2 - PROGRESS: at 59.24% examples, 69534 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:03:38: EPOCH 2 - PROGRESS: at 67.29% examples, 68875 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:03:39: EPOCH 2 - PROGRESS: at 75.37% examples, 68985 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:03:40: EPOCH 2 - PROGRESS: at 83.50% examples, 68830 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:03:42: EPOCH 2 - PROGRESS: at 92.83% examples, 68623 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:03:42: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 22:03:42: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 22:03:42: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:03:42: EPOCH - 2 : training on 1037922 raw words (888155 effective words) took 12.7s, 69789 effective words/s\n",
      "INFO - 22:03:44: EPOCH 3 - PROGRESS: at 8.40% examples, 61200 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:03:45: EPOCH 3 - PROGRESS: at 17.36% examples, 64250 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:03:46: EPOCH 3 - PROGRESS: at 25.95% examples, 68119 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:03:47: EPOCH 3 - PROGRESS: at 34.64% examples, 67786 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:03:48: EPOCH 3 - PROGRESS: at 42.80% examples, 68273 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:03:49: EPOCH 3 - PROGRESS: at 51.72% examples, 68129 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:03:50: EPOCH 3 - PROGRESS: at 60.26% examples, 68424 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:03:51: EPOCH 3 - PROGRESS: at 69.21% examples, 68971 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:03:52: EPOCH 3 - PROGRESS: at 77.31% examples, 68846 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:03:53: EPOCH 3 - PROGRESS: at 85.51% examples, 68810 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:03:54: EPOCH 3 - PROGRESS: at 93.87% examples, 69149 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:03:55: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 22:03:55: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 22:03:55: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:03:55: EPOCH - 3 : training on 1037922 raw words (888049 effective words) took 12.7s, 69719 effective words/s\n",
      "INFO - 22:03:56: EPOCH 4 - PROGRESS: at 8.42% examples, 61237 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:03:57: EPOCH 4 - PROGRESS: at 17.36% examples, 64067 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:03:58: EPOCH 4 - PROGRESS: at 25.03% examples, 66810 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:04:00: EPOCH 4 - PROGRESS: at 33.82% examples, 67174 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:04:01: EPOCH 4 - PROGRESS: at 42.80% examples, 68762 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:04:02: EPOCH 4 - PROGRESS: at 50.84% examples, 68865 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:04:03: EPOCH 4 - PROGRESS: at 59.24% examples, 69276 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:04:04: EPOCH 4 - PROGRESS: at 67.29% examples, 69058 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:04:05: EPOCH 4 - PROGRESS: at 75.37% examples, 68468 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:04:06: EPOCH 4 - PROGRESS: at 84.50% examples, 68505 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:04:07: EPOCH 4 - PROGRESS: at 93.87% examples, 68580 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:04:08: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 22:04:08: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 22:04:08: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:04:08: EPOCH - 4 : training on 1037922 raw words (887560 effective words) took 12.7s, 69872 effective words/s\n",
      "INFO - 22:04:09: EPOCH 5 - PROGRESS: at 8.42% examples, 61243 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:04:10: EPOCH 5 - PROGRESS: at 17.09% examples, 63884 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:04:11: EPOCH 5 - PROGRESS: at 25.95% examples, 69108 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:04:12: EPOCH 5 - PROGRESS: at 33.82% examples, 67271 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:04:13: EPOCH 5 - PROGRESS: at 41.88% examples, 68224 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:04:14: EPOCH 5 - PROGRESS: at 50.69% examples, 67913 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:04:15: EPOCH 5 - PROGRESS: at 59.24% examples, 68675 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:04:17: EPOCH 5 - PROGRESS: at 68.24% examples, 68870 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:04:18: EPOCH 5 - PROGRESS: at 76.34% examples, 68612 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:04:19: EPOCH 5 - PROGRESS: at 85.51% examples, 68685 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:04:20: EPOCH 5 - PROGRESS: at 94.94% examples, 68766 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:04:20: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 22:04:20: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 22:04:20: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:04:20: EPOCH - 5 : training on 1037922 raw words (887657 effective words) took 12.7s, 69781 effective words/s\n",
      "INFO - 22:04:22: EPOCH 6 - PROGRESS: at 8.40% examples, 61492 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:04:23: EPOCH 6 - PROGRESS: at 17.36% examples, 64061 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:04:24: EPOCH 6 - PROGRESS: at 25.95% examples, 68017 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:04:25: EPOCH 6 - PROGRESS: at 33.82% examples, 67548 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:04:26: EPOCH 6 - PROGRESS: at 41.88% examples, 68213 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:04:27: EPOCH 6 - PROGRESS: at 50.78% examples, 68174 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:04:28: EPOCH 6 - PROGRESS: at 59.24% examples, 68770 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:04:29: EPOCH 6 - PROGRESS: at 67.29% examples, 68651 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:04:30: EPOCH 6 - PROGRESS: at 76.34% examples, 68399 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:04:32: EPOCH 6 - PROGRESS: at 85.51% examples, 68661 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:04:33: EPOCH 6 - PROGRESS: at 93.87% examples, 68956 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:04:33: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 22:04:33: worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 22:04:33: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:04:33: EPOCH - 6 : training on 1037922 raw words (887112 effective words) took 12.7s, 69585 effective words/s\n",
      "INFO - 22:04:35: EPOCH 7 - PROGRESS: at 8.42% examples, 61477 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:04:36: EPOCH 7 - PROGRESS: at 17.36% examples, 64381 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:04:37: EPOCH 7 - PROGRESS: at 25.95% examples, 69012 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:04:38: EPOCH 7 - PROGRESS: at 33.82% examples, 68168 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:04:39: EPOCH 7 - PROGRESS: at 42.80% examples, 69784 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:04:40: EPOCH 7 - PROGRESS: at 49.81% examples, 68351 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:04:41: EPOCH 7 - PROGRESS: at 58.26% examples, 69322 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:04:42: EPOCH 7 - PROGRESS: at 66.36% examples, 68972 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:04:43: EPOCH 7 - PROGRESS: at 74.35% examples, 68586 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:04:44: EPOCH 7 - PROGRESS: at 83.50% examples, 68772 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:04:45: EPOCH 7 - PROGRESS: at 91.78% examples, 68635 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:04:46: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 22:04:46: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 22:04:46: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:04:46: EPOCH - 7 : training on 1037922 raw words (888118 effective words) took 12.7s, 69855 effective words/s\n",
      "INFO - 22:04:47: EPOCH 8 - PROGRESS: at 8.47% examples, 60917 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:04:48: EPOCH 8 - PROGRESS: at 17.12% examples, 63734 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:04:49: EPOCH 8 - PROGRESS: at 25.03% examples, 66561 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:04:51: EPOCH 8 - PROGRESS: at 33.82% examples, 66691 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:04:52: EPOCH 8 - PROGRESS: at 41.88% examples, 67691 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:04:53: EPOCH 8 - PROGRESS: at 50.84% examples, 67521 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:04:54: EPOCH 8 - PROGRESS: at 59.24% examples, 67626 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:04:55: EPOCH 8 - PROGRESS: at 68.24% examples, 67535 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:04:56: EPOCH 8 - PROGRESS: at 77.31% examples, 67415 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:04:57: EPOCH 8 - PROGRESS: at 86.54% examples, 67649 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:04:58: EPOCH 8 - PROGRESS: at 94.94% examples, 67513 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:04:59: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 22:04:59: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 22:04:59: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:04:59: EPOCH - 8 : training on 1037922 raw words (887948 effective words) took 13.0s, 68561 effective words/s\n",
      "INFO - 22:05:00: EPOCH 9 - PROGRESS: at 7.50% examples, 71945 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:05:01: EPOCH 9 - PROGRESS: at 14.21% examples, 63790 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:05:02: EPOCH 9 - PROGRESS: at 22.39% examples, 66782 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:05:03: EPOCH 9 - PROGRESS: at 30.78% examples, 66964 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:05:04: EPOCH 9 - PROGRESS: at 39.14% examples, 68343 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:05:05: EPOCH 9 - PROGRESS: at 47.75% examples, 68595 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:05:06: EPOCH 9 - PROGRESS: at 56.36% examples, 69229 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:05:07: EPOCH 9 - PROGRESS: at 63.34% examples, 67760 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:05:08: EPOCH 9 - PROGRESS: at 72.22% examples, 68022 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:05:10: EPOCH 9 - PROGRESS: at 81.41% examples, 68058 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:05:11: EPOCH 9 - PROGRESS: at 90.71% examples, 68381 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:05:12: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 22:05:12: EPOCH 9 - PROGRESS: at 99.14% examples, 68815 words/s, in_qsize 1, out_qsize 1\n",
      "INFO - 22:05:12: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 22:05:12: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:05:12: EPOCH - 9 : training on 1037922 raw words (887882 effective words) took 12.8s, 69338 effective words/s\n",
      "INFO - 22:05:13: EPOCH 10 - PROGRESS: at 7.50% examples, 71403 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:05:14: EPOCH 10 - PROGRESS: at 15.24% examples, 64539 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:05:15: EPOCH 10 - PROGRESS: at 23.26% examples, 66839 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:05:16: EPOCH 10 - PROGRESS: at 31.77% examples, 66942 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:05:17: EPOCH 10 - PROGRESS: at 40.04% examples, 67406 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:05:18: EPOCH 10 - PROGRESS: at 48.77% examples, 67655 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:05:19: EPOCH 10 - PROGRESS: at 57.29% examples, 68048 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:05:20: EPOCH 10 - PROGRESS: at 66.36% examples, 68168 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:05:22: EPOCH 10 - PROGRESS: at 74.35% examples, 67962 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:05:23: EPOCH 10 - PROGRESS: at 82.52% examples, 68225 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:05:24: EPOCH 10 - PROGRESS: at 90.71% examples, 68078 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:05:25: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 22:05:25: EPOCH 10 - PROGRESS: at 99.14% examples, 68258 words/s, in_qsize 1, out_qsize 1\n",
      "INFO - 22:05:25: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 22:05:25: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:05:25: EPOCH - 10 : training on 1037922 raw words (887555 effective words) took 12.9s, 68816 effective words/s\n",
      "INFO - 22:05:25: Doc2Vec lifecycle event {'msg': 'training on 10379220 raw words (8878119 effective words) took 127.9s, 69418 effective words/s', 'datetime': '2021-11-15T22:05:25.160670', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "INFO - 22:05:25: Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 23820 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5', 'datetime': '2021-11-15T22:05:25.161668', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 22:05:26: EPOCH 1 - PROGRESS: at 7.50% examples, 71627 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:05:27: EPOCH 1 - PROGRESS: at 14.21% examples, 62126 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:05:28: EPOCH 1 - PROGRESS: at 22.38% examples, 65574 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:05:29: EPOCH 1 - PROGRESS: at 30.77% examples, 66759 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:05:30: EPOCH 1 - PROGRESS: at 39.14% examples, 68250 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:05:31: EPOCH 1 - PROGRESS: at 47.75% examples, 68362 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:05:32: EPOCH 1 - PROGRESS: at 56.36% examples, 68775 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:05:33: EPOCH 1 - PROGRESS: at 64.40% examples, 68176 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:05:34: EPOCH 1 - PROGRESS: at 73.27% examples, 67991 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:05:35: EPOCH 1 - PROGRESS: at 82.39% examples, 68341 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:05:36: EPOCH 1 - PROGRESS: at 90.71% examples, 68335 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:05:37: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 22:05:37: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 22:05:37: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:05:37: EPOCH - 1 : training on 1037922 raw words (887477 effective words) took 12.8s, 69466 effective words/s\n",
      "INFO - 22:05:39: EPOCH 2 - PROGRESS: at 8.42% examples, 61165 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:05:40: EPOCH 2 - PROGRESS: at 17.12% examples, 63721 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:05:41: EPOCH 2 - PROGRESS: at 25.03% examples, 66494 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:05:42: EPOCH 2 - PROGRESS: at 33.82% examples, 66832 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:05:43: EPOCH 2 - PROGRESS: at 41.88% examples, 68105 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:05:44: EPOCH 2 - PROGRESS: at 50.84% examples, 68246 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:05:45: EPOCH 2 - PROGRESS: at 59.24% examples, 68315 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:05:46: EPOCH 2 - PROGRESS: at 68.24% examples, 68327 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:05:48: EPOCH 2 - PROGRESS: at 77.31% examples, 68295 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:05:49: EPOCH 2 - PROGRESS: at 85.51% examples, 68424 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:05:50: EPOCH 2 - PROGRESS: at 93.87% examples, 68829 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:05:50: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 22:05:50: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 22:05:50: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:05:50: EPOCH - 2 : training on 1037922 raw words (888159 effective words) took 12.8s, 69405 effective words/s\n",
      "INFO - 22:05:52: EPOCH 3 - PROGRESS: at 8.40% examples, 61372 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:05:53: EPOCH 3 - PROGRESS: at 17.36% examples, 64538 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:05:54: EPOCH 3 - PROGRESS: at 25.95% examples, 67749 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:05:55: EPOCH 3 - PROGRESS: at 34.86% examples, 67358 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:05:56: EPOCH 3 - PROGRESS: at 42.80% examples, 67778 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:05:57: EPOCH 3 - PROGRESS: at 51.82% examples, 68035 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:05:58: EPOCH 3 - PROGRESS: at 60.26% examples, 68196 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:05:59: EPOCH 3 - PROGRESS: at 69.21% examples, 68631 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:06:00: EPOCH 3 - PROGRESS: at 78.32% examples, 68363 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:06:02: EPOCH 3 - PROGRESS: at 87.62% examples, 68388 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:06:03: EPOCH 3 - PROGRESS: at 97.04% examples, 68671 words/s, in_qsize 3, out_qsize 0\n",
      "INFO - 22:06:03: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 22:06:03: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 22:06:03: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:06:03: EPOCH - 3 : training on 1037922 raw words (887251 effective words) took 12.7s, 69734 effective words/s\n",
      "INFO - 22:06:04: EPOCH 4 - PROGRESS: at 8.40% examples, 60962 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:06:05: EPOCH 4 - PROGRESS: at 17.36% examples, 64211 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:06:06: EPOCH 4 - PROGRESS: at 25.95% examples, 67791 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:06:08: EPOCH 4 - PROGRESS: at 33.82% examples, 67173 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:06:09: EPOCH 4 - PROGRESS: at 41.88% examples, 68043 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:06:10: EPOCH 4 - PROGRESS: at 50.84% examples, 67961 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:06:11: EPOCH 4 - PROGRESS: at 59.24% examples, 68111 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:06:12: EPOCH 4 - PROGRESS: at 68.24% examples, 68154 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:06:13: EPOCH 4 - PROGRESS: at 77.31% examples, 68121 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:06:14: EPOCH 4 - PROGRESS: at 86.54% examples, 68365 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:06:15: EPOCH 4 - PROGRESS: at 94.94% examples, 68746 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:06:16: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 22:06:16: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 22:06:16: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:06:16: EPOCH - 4 : training on 1037922 raw words (887751 effective words) took 12.8s, 69579 effective words/s\n",
      "INFO - 22:06:17: EPOCH 5 - PROGRESS: at 8.40% examples, 61528 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:06:18: EPOCH 5 - PROGRESS: at 17.09% examples, 64009 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:06:19: EPOCH 5 - PROGRESS: at 25.95% examples, 68840 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:06:20: EPOCH 5 - PROGRESS: at 33.82% examples, 67374 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:06:21: EPOCH 5 - PROGRESS: at 42.80% examples, 69675 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:06:22: EPOCH 5 - PROGRESS: at 49.81% examples, 67975 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:06:23: EPOCH 5 - PROGRESS: at 58.26% examples, 68277 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:06:25: EPOCH 5 - PROGRESS: at 67.29% examples, 68607 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:06:26: EPOCH 5 - PROGRESS: at 75.37% examples, 68812 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:06:27: EPOCH 5 - PROGRESS: at 84.52% examples, 68349 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:06:28: EPOCH 5 - PROGRESS: at 93.87% examples, 68440 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:06:28: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 22:06:28: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 22:06:29: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:06:29: EPOCH - 5 : training on 1037922 raw words (887217 effective words) took 12.7s, 69803 effective words/s\n",
      "INFO - 22:06:30: EPOCH 6 - PROGRESS: at 8.40% examples, 62704 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:06:31: EPOCH 6 - PROGRESS: at 17.36% examples, 64500 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:06:32: EPOCH 6 - PROGRESS: at 25.95% examples, 68202 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:06:33: EPOCH 6 - PROGRESS: at 34.86% examples, 67853 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:06:34: EPOCH 6 - PROGRESS: at 42.80% examples, 68092 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:06:35: EPOCH 6 - PROGRESS: at 51.72% examples, 68263 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:06:36: EPOCH 6 - PROGRESS: at 60.26% examples, 68938 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:06:37: EPOCH 6 - PROGRESS: at 69.21% examples, 69492 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:06:38: EPOCH 6 - PROGRESS: at 76.34% examples, 68564 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:06:40: EPOCH 6 - PROGRESS: at 85.51% examples, 68478 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:06:41: EPOCH 6 - PROGRESS: at 94.94% examples, 68644 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:06:41: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 22:06:41: worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 22:06:41: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:06:41: EPOCH - 6 : training on 1037922 raw words (887201 effective words) took 12.7s, 69731 effective words/s\n",
      "INFO - 22:06:43: EPOCH 7 - PROGRESS: at 8.40% examples, 61038 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:06:44: EPOCH 7 - PROGRESS: at 17.09% examples, 63147 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:06:45: EPOCH 7 - PROGRESS: at 25.96% examples, 67401 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:06:46: EPOCH 7 - PROGRESS: at 33.82% examples, 67082 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:06:47: EPOCH 7 - PROGRESS: at 42.80% examples, 68825 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:06:48: EPOCH 7 - PROGRESS: at 49.80% examples, 67423 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:06:49: EPOCH 7 - PROGRESS: at 58.26% examples, 67830 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:06:50: EPOCH 7 - PROGRESS: at 67.29% examples, 68049 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:06:51: EPOCH 7 - PROGRESS: at 76.34% examples, 68037 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:06:52: EPOCH 7 - PROGRESS: at 85.51% examples, 68029 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:06:54: EPOCH 7 - PROGRESS: at 94.94% examples, 68176 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:06:54: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 22:06:54: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 22:06:54: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:06:54: EPOCH - 7 : training on 1037922 raw words (888289 effective words) took 12.8s, 69473 effective words/s\n",
      "INFO - 22:06:55: EPOCH 8 - PROGRESS: at 8.40% examples, 61600 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:06:56: EPOCH 8 - PROGRESS: at 17.36% examples, 64199 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:06:57: EPOCH 8 - PROGRESS: at 25.03% examples, 66787 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:06:59: EPOCH 8 - PROGRESS: at 33.82% examples, 67284 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:07:00: EPOCH 8 - PROGRESS: at 41.88% examples, 68390 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:07:01: EPOCH 8 - PROGRESS: at 50.84% examples, 68764 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:07:02: EPOCH 8 - PROGRESS: at 59.24% examples, 69198 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:07:03: EPOCH 8 - PROGRESS: at 67.29% examples, 68460 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:07:04: EPOCH 8 - PROGRESS: at 76.34% examples, 68890 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:07:05: EPOCH 8 - PROGRESS: at 85.51% examples, 68837 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:07:06: EPOCH 8 - PROGRESS: at 94.94% examples, 68598 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:07:07: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 22:07:07: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 22:07:07: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:07:07: EPOCH - 8 : training on 1037922 raw words (887350 effective words) took 12.7s, 69661 effective words/s\n",
      "INFO - 22:07:08: EPOCH 9 - PROGRESS: at 8.40% examples, 62410 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:07:09: EPOCH 9 - PROGRESS: at 17.36% examples, 64736 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:07:10: EPOCH 9 - PROGRESS: at 25.03% examples, 67284 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:07:11: EPOCH 9 - PROGRESS: at 33.82% examples, 68005 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:07:12: EPOCH 9 - PROGRESS: at 42.80% examples, 69271 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:07:13: EPOCH 9 - PROGRESS: at 50.84% examples, 68935 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:07:14: EPOCH 9 - PROGRESS: at 59.24% examples, 68935 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:07:16: EPOCH 9 - PROGRESS: at 68.24% examples, 68431 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:07:17: EPOCH 9 - PROGRESS: at 77.31% examples, 68425 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:07:18: EPOCH 9 - PROGRESS: at 86.54% examples, 68665 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:07:19: EPOCH 9 - PROGRESS: at 94.90% examples, 68494 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:07:19: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 22:07:20: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 22:07:20: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:07:20: EPOCH - 9 : training on 1037922 raw words (887920 effective words) took 12.7s, 69699 effective words/s\n",
      "INFO - 22:07:21: EPOCH 10 - PROGRESS: at 8.40% examples, 61309 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:07:22: EPOCH 10 - PROGRESS: at 17.36% examples, 64608 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:07:23: EPOCH 10 - PROGRESS: at 25.95% examples, 68134 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:07:24: EPOCH 10 - PROGRESS: at 34.86% examples, 67754 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:07:25: EPOCH 10 - PROGRESS: at 42.80% examples, 68160 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:07:26: EPOCH 10 - PROGRESS: at 51.72% examples, 68297 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:07:27: EPOCH 10 - PROGRESS: at 60.26% examples, 68934 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:07:28: EPOCH 10 - PROGRESS: at 68.24% examples, 68671 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:07:29: EPOCH 10 - PROGRESS: at 76.34% examples, 68900 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:07:30: EPOCH 10 - PROGRESS: at 84.50% examples, 68677 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:07:32: EPOCH 10 - PROGRESS: at 93.87% examples, 68357 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:07:32: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 22:07:32: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 22:07:32: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:07:32: EPOCH - 10 : training on 1037922 raw words (887261 effective words) took 12.7s, 69798 effective words/s\n",
      "INFO - 22:07:32: Doc2Vec lifecycle event {'msg': 'training on 10379220 raw words (8875876 effective words) took 127.6s, 69552 effective words/s', 'datetime': '2021-11-15T22:07:32.777666', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "INFO - 22:07:32: Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 23820 vocabulary and 100 features, using sg=0 hs=0 sample=0.001 negative=5 window=5', 'datetime': '2021-11-15T22:07:32.777666', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 22:07:34: EPOCH 1 - PROGRESS: at 8.42% examples, 61484 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:07:35: EPOCH 1 - PROGRESS: at 17.36% examples, 64318 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:07:36: EPOCH 1 - PROGRESS: at 25.95% examples, 68919 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:07:37: EPOCH 1 - PROGRESS: at 33.82% examples, 67455 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:07:38: EPOCH 1 - PROGRESS: at 41.88% examples, 68266 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:07:39: EPOCH 1 - PROGRESS: at 50.84% examples, 68356 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:07:40: EPOCH 1 - PROGRESS: at 59.24% examples, 68686 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:07:41: EPOCH 1 - PROGRESS: at 68.24% examples, 68673 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:07:42: EPOCH 1 - PROGRESS: at 77.31% examples, 68611 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:07:44: EPOCH 1 - PROGRESS: at 86.54% examples, 68646 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:07:45: EPOCH 1 - PROGRESS: at 94.94% examples, 68733 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:07:45: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 22:07:45: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 22:07:45: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:07:45: EPOCH - 1 : training on 1037922 raw words (888437 effective words) took 12.7s, 69800 effective words/s\n",
      "INFO - 22:07:46: EPOCH 2 - PROGRESS: at 8.40% examples, 61667 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:07:47: EPOCH 2 - PROGRESS: at 17.36% examples, 64037 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:07:48: EPOCH 2 - PROGRESS: at 25.03% examples, 66635 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:07:50: EPOCH 2 - PROGRESS: at 33.82% examples, 67219 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:07:51: EPOCH 2 - PROGRESS: at 41.88% examples, 68362 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:07:52: EPOCH 2 - PROGRESS: at 50.84% examples, 68361 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:07:53: EPOCH 2 - PROGRESS: at 59.24% examples, 68622 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:07:54: EPOCH 2 - PROGRESS: at 68.24% examples, 68582 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:07:55: EPOCH 2 - PROGRESS: at 77.31% examples, 68529 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:07:56: EPOCH 2 - PROGRESS: at 86.54% examples, 68656 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:07:57: EPOCH 2 - PROGRESS: at 94.94% examples, 68955 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:07:58: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 22:07:58: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 22:07:58: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:07:58: EPOCH - 2 : training on 1037922 raw words (888241 effective words) took 12.7s, 69737 effective words/s\n",
      "INFO - 22:07:59: EPOCH 3 - PROGRESS: at 8.42% examples, 61389 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:08:00: EPOCH 3 - PROGRESS: at 17.36% examples, 64494 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:08:01: EPOCH 3 - PROGRESS: at 25.95% examples, 67944 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:08:02: EPOCH 3 - PROGRESS: at 33.82% examples, 67851 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:08:03: EPOCH 3 - PROGRESS: at 42.80% examples, 68846 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:08:04: EPOCH 3 - PROGRESS: at 51.82% examples, 68984 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:08:06: EPOCH 3 - PROGRESS: at 60.26% examples, 69040 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:08:07: EPOCH 3 - PROGRESS: at 68.24% examples, 68638 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:08:08: EPOCH 3 - PROGRESS: at 77.31% examples, 68492 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:08:09: EPOCH 3 - PROGRESS: at 86.54% examples, 68436 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:08:10: EPOCH 3 - PROGRESS: at 95.97% examples, 68549 words/s, in_qsize 4, out_qsize 0\n",
      "INFO - 22:08:10: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 22:08:11: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 22:08:11: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:08:11: EPOCH - 3 : training on 1037922 raw words (887433 effective words) took 12.7s, 69634 effective words/s\n",
      "INFO - 22:08:12: EPOCH 4 - PROGRESS: at 8.40% examples, 61001 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:08:13: EPOCH 4 - PROGRESS: at 17.12% examples, 63604 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:08:14: EPOCH 4 - PROGRESS: at 25.03% examples, 66626 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:08:15: EPOCH 4 - PROGRESS: at 33.82% examples, 66939 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:08:16: EPOCH 4 - PROGRESS: at 41.88% examples, 67972 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:08:17: EPOCH 4 - PROGRESS: at 50.84% examples, 67987 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:08:18: EPOCH 4 - PROGRESS: at 59.24% examples, 68246 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:08:19: EPOCH 4 - PROGRESS: at 68.24% examples, 68298 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:08:21: EPOCH 4 - PROGRESS: at 77.31% examples, 68271 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:08:22: EPOCH 4 - PROGRESS: at 86.54% examples, 68659 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:08:23: EPOCH 4 - PROGRESS: at 94.94% examples, 68605 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:08:23: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 22:08:23: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 22:08:23: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:08:23: EPOCH - 4 : training on 1037922 raw words (887196 effective words) took 12.7s, 69721 effective words/s\n",
      "INFO - 22:08:25: EPOCH 5 - PROGRESS: at 8.40% examples, 62210 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:08:26: EPOCH 5 - PROGRESS: at 17.36% examples, 65028 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:08:27: EPOCH 5 - PROGRESS: at 25.95% examples, 68145 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:08:28: EPOCH 5 - PROGRESS: at 34.86% examples, 68075 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:08:29: EPOCH 5 - PROGRESS: at 42.80% examples, 68585 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:08:30: EPOCH 5 - PROGRESS: at 51.82% examples, 68669 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:08:31: EPOCH 5 - PROGRESS: at 60.26% examples, 68634 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:08:32: EPOCH 5 - PROGRESS: at 68.24% examples, 68824 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:08:33: EPOCH 5 - PROGRESS: at 77.31% examples, 68389 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:08:35: EPOCH 5 - PROGRESS: at 86.54% examples, 68068 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:08:36: EPOCH 5 - PROGRESS: at 95.97% examples, 67921 words/s, in_qsize 4, out_qsize 0\n",
      "INFO - 22:08:36: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 22:08:36: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 22:08:36: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:08:36: EPOCH - 5 : training on 1037922 raw words (887501 effective words) took 12.8s, 69160 effective words/s\n",
      "INFO - 22:08:37: EPOCH 6 - PROGRESS: at 8.40% examples, 59837 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:08:39: EPOCH 6 - PROGRESS: at 17.36% examples, 62926 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:08:40: EPOCH 6 - PROGRESS: at 25.03% examples, 65599 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:08:41: EPOCH 6 - PROGRESS: at 33.82% examples, 66077 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:08:42: EPOCH 6 - PROGRESS: at 41.88% examples, 67177 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:08:43: EPOCH 6 - PROGRESS: at 50.84% examples, 67373 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:08:44: EPOCH 6 - PROGRESS: at 59.24% examples, 67594 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:08:45: EPOCH 6 - PROGRESS: at 68.24% examples, 67370 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:08:46: EPOCH 6 - PROGRESS: at 77.31% examples, 66585 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:08:48: EPOCH 6 - PROGRESS: at 86.54% examples, 66953 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:08:49: EPOCH 6 - PROGRESS: at 94.94% examples, 67289 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:08:49: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 22:08:49: worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 22:08:49: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:08:49: EPOCH - 6 : training on 1037922 raw words (886859 effective words) took 13.0s, 68048 effective words/s\n",
      "INFO - 22:08:50: EPOCH 7 - PROGRESS: at 5.79% examples, 54919 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:08:51: EPOCH 7 - PROGRESS: at 14.21% examples, 56813 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:08:52: EPOCH 7 - PROGRESS: at 22.39% examples, 61341 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:08:54: EPOCH 7 - PROGRESS: at 30.77% examples, 61857 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:08:55: EPOCH 7 - PROGRESS: at 39.14% examples, 62005 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:08:56: EPOCH 7 - PROGRESS: at 46.73% examples, 62670 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:08:57: EPOCH 7 - PROGRESS: at 53.58% examples, 62276 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:08:58: EPOCH 7 - PROGRESS: at 62.29% examples, 62589 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:08:59: EPOCH 7 - PROGRESS: at 71.20% examples, 63096 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:09:00: EPOCH 7 - PROGRESS: at 79.33% examples, 63732 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:09:01: EPOCH 7 - PROGRESS: at 86.54% examples, 63662 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:09:02: EPOCH 7 - PROGRESS: at 94.90% examples, 63702 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:09:03: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 22:09:03: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 22:09:03: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:09:03: EPOCH - 7 : training on 1037922 raw words (888291 effective words) took 13.6s, 65085 effective words/s\n",
      "INFO - 22:09:04: EPOCH 8 - PROGRESS: at 8.42% examples, 59865 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:09:05: EPOCH 8 - PROGRESS: at 17.09% examples, 63160 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:09:06: EPOCH 8 - PROGRESS: at 25.03% examples, 64850 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:09:08: EPOCH 8 - PROGRESS: at 33.82% examples, 64245 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:09:09: EPOCH 8 - PROGRESS: at 41.88% examples, 64364 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:09:10: EPOCH 8 - PROGRESS: at 50.84% examples, 64555 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:09:11: EPOCH 8 - PROGRESS: at 59.24% examples, 65104 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:09:12: EPOCH 8 - PROGRESS: at 67.29% examples, 65476 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:09:13: EPOCH 8 - PROGRESS: at 75.37% examples, 65832 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:09:14: EPOCH 8 - PROGRESS: at 83.50% examples, 66054 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:09:15: EPOCH 8 - PROGRESS: at 90.71% examples, 65639 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:09:16: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 22:09:16: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 22:09:16: EPOCH 8 - PROGRESS: at 100.00% examples, 66772 words/s, in_qsize 0, out_qsize 1\n",
      "INFO - 22:09:16: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:09:16: EPOCH - 8 : training on 1037922 raw words (887412 effective words) took 13.3s, 66767 effective words/s\n",
      "INFO - 22:09:17: EPOCH 9 - PROGRESS: at 8.42% examples, 60170 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:09:19: EPOCH 9 - PROGRESS: at 17.36% examples, 63064 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:09:20: EPOCH 9 - PROGRESS: at 25.03% examples, 65596 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:09:21: EPOCH 9 - PROGRESS: at 33.82% examples, 66004 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:09:22: EPOCH 9 - PROGRESS: at 41.87% examples, 66952 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:09:23: EPOCH 9 - PROGRESS: at 50.84% examples, 67376 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:09:24: EPOCH 9 - PROGRESS: at 59.24% examples, 67486 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:09:25: EPOCH 9 - PROGRESS: at 68.24% examples, 67953 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:09:26: EPOCH 9 - PROGRESS: at 76.34% examples, 68166 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:09:27: EPOCH 9 - PROGRESS: at 85.51% examples, 67726 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:09:29: EPOCH 9 - PROGRESS: at 94.90% examples, 67804 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:09:29: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 22:09:29: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 22:09:29: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:09:29: EPOCH - 9 : training on 1037922 raw words (887695 effective words) took 12.9s, 69049 effective words/s\n",
      "INFO - 22:09:30: EPOCH 10 - PROGRESS: at 8.40% examples, 61269 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:09:31: EPOCH 10 - PROGRESS: at 17.36% examples, 64142 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:09:32: EPOCH 10 - PROGRESS: at 25.03% examples, 66684 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:09:34: EPOCH 10 - PROGRESS: at 33.82% examples, 66960 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:09:35: EPOCH 10 - PROGRESS: at 41.88% examples, 68132 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:09:36: EPOCH 10 - PROGRESS: at 50.84% examples, 68134 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:09:37: EPOCH 10 - PROGRESS: at 59.24% examples, 68493 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:09:38: EPOCH 10 - PROGRESS: at 67.29% examples, 68738 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:09:39: EPOCH 10 - PROGRESS: at 75.37% examples, 68664 words/s, in_qsize 5, out_qsize 0\n",
      "INFO - 22:09:40: EPOCH 10 - PROGRESS: at 83.50% examples, 68622 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:09:41: EPOCH 10 - PROGRESS: at 91.78% examples, 67964 words/s, in_qsize 6, out_qsize 0\n",
      "INFO - 22:09:42: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 22:09:42: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 22:09:42: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 22:09:42: EPOCH - 10 : training on 1037922 raw words (888076 effective words) took 12.8s, 69117 effective words/s\n",
      "INFO - 22:09:42: Doc2Vec lifecycle event {'msg': 'training on 10379220 raw words (8877141 effective words) took 129.6s, 68515 effective words/s', 'datetime': '2021-11-15T22:09:42.343669', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "INFO - 22:09:42: Doc2Vec lifecycle event {'fname_or_handle': 'd2v.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2021-11-15T22:09:42.343669', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'saving'}\n",
      "INFO - 22:09:42: storing np array 'vectors' to d2v.model.dv.vectors.npy\n",
      "INFO - 22:09:44: not storing attribute cum_table\n",
      "INFO - 22:09:44: saved d2v.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "max_epochs = 5\n",
    "vec_size = 100\n",
    "alpha = 0.025\n",
    "\n",
    "model_doc = Doc2Vec(vector_size=vec_size,\n",
    "                alpha=alpha, \n",
    "                min_alpha=0.00025,\n",
    "                min_count=1,\n",
    "                dm=1)\n",
    "  \n",
    "model_doc.build_vocab(tagged_data)\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "    print('iteration {0}'.format(epoch))\n",
    "    model_doc.train(tagged_data,\n",
    "                total_examples=model_doc.corpus_count,\n",
    "                epochs=10)\n",
    "    # decrease the learning rate\n",
    "    model_doc.alpha -= 0.0002\n",
    "    # fix the learning rate, no decay\n",
    "    model_doc.min_alpha = model_doc.alpha\n",
    "\n",
    "model_doc.save(\"d2v.model\")\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b1c4d0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 22:11:19: loading Doc2Vec object from d2v.model\n",
      "INFO - 22:11:20: loading dv recursively from d2v.model.dv.* with mmap=None\n",
      "INFO - 22:11:20: loading vectors from d2v.model.dv.vectors.npy with mmap=None\n",
      "INFO - 22:11:20: loading wv recursively from d2v.model.wv.* with mmap=None\n",
      "INFO - 22:11:20: setting ignored attribute cum_table to None\n",
      "INFO - 22:11:20: Doc2Vec lifecycle event {'fname': 'd2v.model', 'datetime': '2021-11-15T22:11:20.487568', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'loaded'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "infervector :  [-1.0948300e-03 -3.0130588e-03 -3.2158128e-03 -2.2336596e-03\n",
      " -5.6902436e-04  4.9792505e-03 -4.1479487e-03  3.2444722e-03\n",
      " -9.8201213e-04  3.8267256e-04  4.2805420e-03 -3.8736034e-03\n",
      " -1.0155964e-03 -2.7353568e-03  3.1132514e-03 -7.4538676e-04\n",
      "  4.6149306e-03  2.1108382e-03 -1.8934292e-03 -4.5531355e-03\n",
      "  4.1035544e-03 -1.3906566e-03 -2.0570979e-03 -2.9974764e-03\n",
      "  2.5853992e-04 -2.4875125e-03 -3.9584483e-03 -2.5457137e-03\n",
      "  9.5643580e-04 -3.4371475e-03  6.3641608e-04 -2.5162857e-03\n",
      "  1.7685771e-04 -2.5888109e-03 -2.8173574e-03 -3.1098926e-03\n",
      " -7.1257085e-04  3.1269651e-03 -4.7572041e-03  1.5845734e-03\n",
      " -4.5119881e-04 -2.8822795e-03 -1.3190350e-03  2.7068586e-03\n",
      " -1.1087060e-05 -2.3971272e-03 -9.5118879e-04 -2.3176745e-03\n",
      "  8.6905004e-04  2.5868844e-03  2.3079335e-03  4.1183513e-03\n",
      " -3.6493273e-04  3.5040551e-03  1.7143232e-03  9.4479322e-04\n",
      "  1.4545619e-03 -8.7448000e-04 -1.8480078e-03  3.2277023e-03\n",
      " -2.9682785e-03  8.0378650e-04  1.7610121e-03 -3.6347837e-03\n",
      " -1.7924603e-03  3.9526280e-03  1.2916726e-03 -3.0120302e-03\n",
      "  1.3267010e-03  1.6395121e-03 -4.7554420e-03  3.4854228e-03\n",
      " -4.0555792e-03 -4.9935252e-04 -2.3869458e-03  2.1212690e-03\n",
      " -3.9202478e-03 -4.8706797e-03  9.8370016e-04  3.1061601e-03\n",
      " -2.9606891e-03  5.4622888e-05  1.5176773e-03  4.2277742e-03\n",
      " -2.0636010e-03 -2.0185006e-03 -2.0295796e-03 -1.2214744e-03\n",
      "  2.4224049e-03 -4.5324760e-03 -3.6577228e-03 -4.2149057e-03\n",
      "  1.6483748e-03 -6.6616712e-04 -1.1354649e-03 -2.1412598e-03\n",
      " -1.8140412e-03  1.6361714e-04 -2.4856017e-03 -4.8706690e-03]\n"
     ]
    }
   ],
   "source": [
    "# let's play around a bit\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec\n",
    "\n",
    "model_doc= Doc2Vec.load(\"d2v.model\")\n",
    "\n",
    "test_data = word_tokenize(\"software\".lower())\n",
    "infervector = model_doc.infer_vector(test_data)\n",
    "print(\"infervector : \", infervector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "7ebf079f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('engineer', 0.7792899012565613),\n",
       " ('consultant', 0.767435610294342),\n",
       " ('programmer', 0.7430940866470337),\n",
       " ('development', 0.7413915395736694),\n",
       " ('software', 0.736546516418457),\n",
       " ('architect', 0.7362387180328369),\n",
       " ('designer', 0.7341099977493286),\n",
       " ('analyst', 0.7284877896308899),\n",
       " ('web', 0.7136134505271912),\n",
       " ('systems', 0.7085645198822021)]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_doc.wv.most_similar('developer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "717035b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('engineering', 0.8313654065132141),\n",
       " ('consultant', 0.8232923150062561),\n",
       " ('analyst', 0.8065841197967529),\n",
       " ('architect', 0.7996267676353455),\n",
       " ('specialist', 0.7960496544837952),\n",
       " ('manager', 0.7815800905227661),\n",
       " ('developer', 0.779289960861206),\n",
       " ('administrator', 0.76097172498703),\n",
       " ('lead', 0.7426279783248901),\n",
       " ('systems', 0.7195594310760498)]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_doc.wv.most_similar('engineer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2170edfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('119566', 0.8511234521865845), ('231802', 0.8401719927787781), ('211635', 0.8395752906799316), ('57096', 0.8387839794158936), ('248778', 0.8378311991691589), ('182380', 0.8162076473236084), ('183983', 0.8134768605232239), ('96816', 0.8097153902053833), ('214154', 0.8094416856765747), ('181138', 0.8081831336021423)]\n"
     ]
    }
   ],
   "source": [
    "query = \"software engineer\".split()\n",
    "\n",
    "new_vector = model_doc.infer_vector(query)\n",
    "sims = model_doc.dv.most_similar([new_vector])\n",
    "print(sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "df301b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_vector = model_doc.infer_vector([\"software\", \"engineer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "7d6481d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00085565 -0.00447602  0.00162773  0.0047522  -0.00311977 -0.00454217\n",
      "  0.00238067 -0.00409617 -0.003526    0.00446138  0.00213109 -0.00324883\n",
      "  0.00275442  0.00182354 -0.00126268  0.00374277 -0.00459501 -0.00462416\n",
      "  0.00369988 -0.00330196  0.00218844  0.00129127 -0.00461516 -0.00436336\n",
      "  0.00318492  0.00330207  0.00478095  0.00369216 -0.00386617  0.00446906\n",
      "  0.00144897  0.00367969  0.00378462  0.00278455  0.00077458  0.00353155\n",
      " -0.00370056  0.00021552 -0.00158209  0.00303996  0.00493509  0.00092773\n",
      " -0.00475027  0.00389528  0.00340583  0.00445411  0.00072603 -0.00418299\n",
      "  0.00078716 -0.00256898 -0.00034733 -0.00125732  0.00125496  0.00381139\n",
      "  0.00451908  0.00480799  0.0045063  -0.00376669  0.0042793  -0.00275833\n",
      " -0.00166    -0.0034785   0.00076885  0.00340302 -0.00140343  0.00236112\n",
      " -0.00482351 -0.00432416  0.00395162 -0.00080143  0.0035865   0.00063031\n",
      "  0.0018056   0.00411497  0.00456712  0.00406306 -0.00291419  0.00050661\n",
      " -0.00323906 -0.00068642  0.00291761  0.00475291  0.00157556  0.00337896\n",
      " -0.00428086  0.0039443   0.00270059  0.00097648 -0.0029094   0.00487802\n",
      " -0.00350587  0.00231624  0.00154333 -0.00301661  0.00085506  0.00031911\n",
      " -0.00034983 -0.00362464 -0.00326744 -0.00499943]\n"
     ]
    }
   ],
   "source": [
    "print(new_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "443de290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('co-founder', 0.8362897634506226),\n",
       " ('cofounder', 0.6949377655982971),\n",
       " ('owner', 0.6782577633857727),\n",
       " ('creative', 0.6626403331756592),\n",
       " ('ceo', 0.6604053378105164),\n",
       " ('media', 0.636041522026062),\n",
       " ('e-commerce', 0.6242018342018127),\n",
       " ('community', 0.6128408312797546),\n",
       " ('web', 0.5908872485160828),\n",
       " ('designer', 0.5895556211471558)]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_doc.wv.similar_by_word('founder', topn=10, restrict_vocab=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27893dd1",
   "metadata": {},
   "source": [
    "###### ----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8ebc2dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  use this query to compare job titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "694efe12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medium Similarity! Score:  0.6312029\n"
     ]
    }
   ],
   "source": [
    "q1 = ('product owner')\n",
    "q2 = ('ui engineer')\n",
    "score = model_doc.wv.n_similarity(q1.split(), q2.split())\n",
    "\n",
    "# now for the similarity variable\n",
    "\n",
    "if score==1.0:\n",
    "    print(\"They're the same! Score: \", score)\n",
    "elif score<=0.99 and score>=0.9:\n",
    "    print(\"Very High Similarity! Score: \", score)\n",
    "elif score<=0.89 and score>=0.75:\n",
    "    print(\"High Similarity! Score: \", score)\n",
    "elif score<=0.74 and score>=0.50:\n",
    "    print(\"Medium Similarity! Score: \", score)\n",
    "elif score<=0.49 and score>=0.30:\n",
    "    print(\"Low-ish Similarity! Score: \", score)\n",
    "else:\n",
    "    print(\"Would'nt call them similar! Score: \", score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe2ad27",
   "metadata": {},
   "source": [
    "###### So far the best results have come from this model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec801159",
   "metadata": {},
   "source": [
    "###### --------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1be243",
   "metadata": {},
   "source": [
    "###### Using the pre-trained GoogleNews model to fine tune around the same dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5ccd60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now lets try the same dataset using a pre-trained word2vec model\n",
    "#We will be using the GoogleNews vectors dataset at \n",
    "#https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?resourcekey=0-wjGZdNAUop6WykTtMip30g\n",
    "\n",
    "#download this to working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8170f66f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cbf07e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "from collections import defaultdict\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0f15fa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.models import Word2Vec \n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3c4cd262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find current working directory\n",
    "directory = os.getcwd()\n",
    "\n",
    "# specifying csv filename, this is a switch between two datasets in the directory.\n",
    "\n",
    "# filename = \"\\\\job_title.csv\"\n",
    "filename = \"\\\\titles_final.csv\"\n",
    "\n",
    "# using concat to generate fullpath\n",
    "file = directory+filename\n",
    "\n",
    "# load csv file containing job titles\n",
    "df = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0bb21871",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentences2 = df['Titles'].astype('str').tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a80a8394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['senior', 'product', 'manager'], ['solutions', 'engineer'], ['staff', 'software', 'engineer'], ['head', 'of', 'product', 'platform'], ['incubation', 'lead', 'success', 'cloud'], ['author'], ['technical', 'writer'], ['product'], ['technology', 'architecture', 'and', 'operations'], ['software', 'engineer']]\n"
     ]
    }
   ],
   "source": [
    "# tokenize the dataset\n",
    "tokenizer2 = RegexpTokenizer(r'\\w+')\n",
    "df_tokenized2 = [w.lower() for w in df_sentences2]\n",
    "df_tokenized2 = [tokenizer.tokenize(i) for i in df_tokenized2]\n",
    "\n",
    "print(df_tokenized2[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a335d03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 21:22:34: loading projection weights from GoogleNews-vectors-negative300.bin\n",
      "INFO - 21:22:58: KeyedVectors lifecycle event {'msg': 'loaded (3000000, 300) matrix of type float32 from GoogleNews-vectors-negative300.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2021-11-15T21:22:58.951608', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'load_word2vec_format'}\n"
     ]
    }
   ],
   "source": [
    "# loading pretrained model unto the script\n",
    "\n",
    "model_keyed = KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin\", binary = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2d023e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 21:24:01: Word2Vec lifecycle event {'params': 'Word2Vec(vocab=0, vector_size=300, alpha=0.025)', 'datetime': '2021-11-15T21:24:01.868482', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n",
      "INFO - 21:24:01: collecting all words and their counts\n",
      "INFO - 21:24:01: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 21:24:01: PROGRESS: at sentence #10000, processed 39523 words, keeping 2026 word types\n",
      "INFO - 21:24:01: PROGRESS: at sentence #20000, processed 76873 words, keeping 2903 word types\n",
      "INFO - 21:24:01: PROGRESS: at sentence #30000, processed 112308 words, keeping 3562 word types\n",
      "INFO - 21:24:01: PROGRESS: at sentence #40000, processed 145434 words, keeping 4058 word types\n",
      "INFO - 21:24:01: PROGRESS: at sentence #50000, processed 176505 words, keeping 4505 word types\n",
      "INFO - 21:24:01: PROGRESS: at sentence #60000, processed 214131 words, keeping 5104 word types\n",
      "INFO - 21:24:01: PROGRESS: at sentence #70000, processed 250914 words, keeping 5677 word types\n",
      "INFO - 21:24:01: PROGRESS: at sentence #80000, processed 286100 words, keeping 6221 word types\n",
      "INFO - 21:24:01: PROGRESS: at sentence #90000, processed 319355 words, keeping 6696 word types\n",
      "INFO - 21:24:01: PROGRESS: at sentence #100000, processed 351220 words, keeping 7176 word types\n",
      "INFO - 21:24:01: PROGRESS: at sentence #110000, processed 386805 words, keeping 7642 word types\n",
      "INFO - 21:24:01: PROGRESS: at sentence #120000, processed 422869 words, keeping 8086 word types\n",
      "INFO - 21:24:01: PROGRESS: at sentence #130000, processed 457500 words, keeping 8535 word types\n",
      "INFO - 21:24:01: PROGRESS: at sentence #140000, processed 489898 words, keeping 8929 word types\n",
      "INFO - 21:24:01: PROGRESS: at sentence #150000, processed 521468 words, keeping 9398 word types\n",
      "INFO - 21:24:01: PROGRESS: at sentence #160000, processed 556061 words, keeping 9773 word types\n",
      "INFO - 21:24:02: PROGRESS: at sentence #170000, processed 590603 words, keeping 10177 word types\n",
      "INFO - 21:24:02: PROGRESS: at sentence #180000, processed 623293 words, keeping 10537 word types\n",
      "INFO - 21:24:02: PROGRESS: at sentence #190000, processed 654701 words, keeping 10990 word types\n",
      "INFO - 21:24:02: PROGRESS: at sentence #200000, processed 687629 words, keeping 11408 word types\n",
      "INFO - 21:24:02: PROGRESS: at sentence #210000, processed 720893 words, keeping 11781 word types\n",
      "INFO - 21:24:02: PROGRESS: at sentence #220000, processed 751986 words, keeping 12238 word types\n",
      "INFO - 21:24:02: PROGRESS: at sentence #230000, processed 784276 words, keeping 12639 word types\n",
      "INFO - 21:24:02: PROGRESS: at sentence #240000, processed 816114 words, keeping 13024 word types\n",
      "INFO - 21:24:02: PROGRESS: at sentence #250000, processed 847205 words, keeping 13491 word types\n",
      "INFO - 21:24:02: PROGRESS: at sentence #260000, processed 878857 words, keeping 13909 word types\n",
      "INFO - 21:24:02: PROGRESS: at sentence #270000, processed 910038 words, keeping 14356 word types\n",
      "INFO - 21:24:02: PROGRESS: at sentence #280000, processed 940756 words, keeping 14745 word types\n",
      "INFO - 21:24:02: PROGRESS: at sentence #290000, processed 971447 words, keeping 15250 word types\n",
      "INFO - 21:24:02: collected 15653 word types from a corpus of 997464 raw words and 298396 sentences\n",
      "INFO - 21:24:02: Creating a fresh vocabulary\n",
      "INFO - 21:24:02: Word2Vec lifecycle event {'msg': 'effective_min_count=1 retains 15653 unique words (100.0%% of original 15653, drops 0)', 'datetime': '2021-11-15T21:24:02.173482', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "INFO - 21:24:02: Word2Vec lifecycle event {'msg': 'effective_min_count=1 leaves 997464 word corpus (100.0%% of original 997464, drops 0)', 'datetime': '2021-11-15T21:24:02.173482', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "INFO - 21:24:02: deleting the raw counts dictionary of 15653 items\n",
      "INFO - 21:24:02: sample=0.001 downsamples 62 most-common words\n",
      "INFO - 21:24:02: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 562082.8259107231 word corpus (56.4%% of prior 997464)', 'datetime': '2021-11-15T21:24:02.258482', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "INFO - 21:24:02: estimated required memory for 15653 words and 300 dimensions: 45393700 bytes\n",
      "INFO - 21:24:02: resetting layer weights\n",
      "INFO - 21:24:02: Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2021-11-15T21:24:02.424482', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'build_vocab'}\n",
      "INFO - 21:24:02: collecting all words and their counts\n",
      "INFO - 21:24:02: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 21:24:03: collected 3000000 word types from a corpus of 3000000 raw words and 1 sentences\n",
      "INFO - 21:24:03: Updating model with new vocabulary\n",
      "INFO - 21:24:18: Word2Vec lifecycle event {'msg': 'added 2990501 new unique words (99.68336666666667%% of original 3000000) and increased the count of 9499 pre-existing words (0.3166333333333333%% of original 3000000)', 'datetime': '2021-11-15T21:24:18.734480', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "INFO - 21:24:33: deleting the raw counts dictionary of 3000000 items\n",
      "INFO - 21:24:33: sample=0.001 downsamples 0 most-common words\n",
      "INFO - 21:24:33: Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 3000000 word corpus (100.0%% of prior 3000000)', 'datetime': '2021-11-15T21:24:33.967481', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "INFO - 21:24:56: estimated required memory for 3000000 words and 300 dimensions: 8700000000 bytes\n",
      "INFO - 21:24:56: updating layer weights\n",
      "INFO - 21:25:17: Word2Vec lifecycle event {'update': True, 'trim_rule': 'None', 'datetime': '2021-11-15T21:25:17.336247', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'build_vocab'}\n",
      "INFO - 21:25:20: loading projection weights from GoogleNews-vectors-negative300.bin\n",
      "INFO - 21:25:47: KeyedVectors lifecycle event {'msg': 'loaded (3000000, 300) matrix of type float32 from GoogleNews-vectors-negative300.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2021-11-15T21:25:47.813593', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'load_word2vec_format'}\n",
      "INFO - 21:25:48: Word2Vec lifecycle event {'msg': 'training model with 4 workers on 3006154 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5', 'datetime': '2021-11-15T21:25:48.378952', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "INFO - 21:25:53: EPOCH 1 - PROGRESS: at 0.82% examples, 3617 words/s, in_qsize 7, out_qsize 0\n",
      "INFO - 21:25:54: EPOCH 1 - PROGRESS: at 32.30% examples, 90106 words/s, in_qsize 7, out_qsize 0\n",
      "INFO - 21:25:56: EPOCH 1 - PROGRESS: at 66.28% examples, 109063 words/s, in_qsize 8, out_qsize 0\n",
      "INFO - 21:25:57: EPOCH 1 - PROGRESS: at 88.28% examples, 122291 words/s, in_qsize 7, out_qsize 0\n",
      "INFO - 21:25:57: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 21:25:57: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 21:25:57: worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 21:25:57: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 21:25:57: EPOCH - 1 : training on 997464 raw words (982036 effective words) took 7.3s, 134581 effective words/s\n",
      "INFO - 21:25:59: EPOCH 2 - PROGRESS: at 59.97% examples, 607859 words/s, in_qsize 7, out_qsize 0\n",
      "INFO - 21:25:59: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 21:25:59: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 21:25:59: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 21:25:59: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 21:25:59: EPOCH - 2 : training on 997464 raw words (982020 effective words) took 1.5s, 640000 effective words/s\n",
      "INFO - 21:26:00: EPOCH 3 - PROGRESS: at 63.15% examples, 638565 words/s, in_qsize 7, out_qsize 0\n",
      "INFO - 21:26:01: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 21:26:01: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 21:26:01: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 21:26:01: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 21:26:01: EPOCH - 3 : training on 997464 raw words (982025 effective words) took 1.5s, 645110 effective words/s\n",
      "INFO - 21:26:02: EPOCH 4 - PROGRESS: at 68.24% examples, 687524 words/s, in_qsize 7, out_qsize 0\n",
      "INFO - 21:26:02: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 21:26:02: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 21:26:02: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 21:26:02: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 21:26:02: EPOCH - 4 : training on 997464 raw words (982070 effective words) took 1.4s, 699353 effective words/s\n",
      "INFO - 21:26:03: EPOCH 5 - PROGRESS: at 66.28% examples, 669096 words/s, in_qsize 7, out_qsize 0\n",
      "INFO - 21:26:04: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 21:26:04: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 21:26:04: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 21:26:04: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 21:26:04: EPOCH - 5 : training on 997464 raw words (982119 effective words) took 1.5s, 676791 effective words/s\n",
      "INFO - 21:26:04: Word2Vec lifecycle event {'msg': 'training on 4987320 raw words (4910270 effective words) took 15.7s, 313595 effective words/s', 'datetime': '2021-11-15T21:26:04.038384', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "INFO - 21:26:04: Word2Vec lifecycle event {'fname_or_handle': 'c2vpretrained.model', 'separately': 'None', 'sep_limit': 10485760, 'ignore': frozenset(), 'datetime': '2021-11-15T21:26:04.042384', 'gensim': '4.0.1', 'python': '3.6.13 |Anaconda, Inc.| (default, Mar 16 2021, 11:37:27) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'saving'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 2.04 mins\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 21:26:04: storing np array 'vectors' to c2vpretrained.model.wv.vectors.npy\n",
      "INFO - 21:27:35: storing np array 'syn1neg' to c2vpretrained.model.syn1neg.npy\n",
      "INFO - 21:28:45: not storing attribute cum_table\n",
      "INFO - 21:28:50: saved c2vpretrained.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved!\n"
     ]
    }
   ],
   "source": [
    "# Building vocabulary and training the model\n",
    "\n",
    "t = time()\n",
    "\n",
    "model_2 = Word2Vec(vector_size=300, min_count=1, workers=4)\n",
    "model_2.build_vocab(df_tokenized2)\n",
    "total_examples = model_2.corpus_count\n",
    "\n",
    "model_2.build_vocab([list(model_keyed.index_to_key)], update=True)\n",
    "\n",
    "model_2.wv.load_word2vec_format(\"GoogleNews-vectors-negative300.bin\", binary=True)\n",
    "\n",
    "model_2.train(df_tokenized2, total_examples=total_examples, epochs=5)\n",
    "\n",
    "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))\n",
    "\n",
    "model_2.save('c2vpretrained.model')\n",
    "print(\"model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "cc6aa470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('mobile', 0.9679745435714722),\n",
       " ('driver', 0.9671269059181213),\n",
       " ('web', 0.9640653729438782),\n",
       " ('application', 0.9639647006988525),\n",
       " ('platform', 0.9580212235450745),\n",
       " ('ops', 0.9522882699966431),\n",
       " ('applications', 0.9518682956695557),\n",
       " ('industrial', 0.9515718221664429),\n",
       " ('process', 0.9483321905136108),\n",
       " ('consulting', 0.9479199647903442)]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's do some testing\n",
    "\n",
    "model_2.wv.most_similar('software', topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "34f179da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['senior',\n",
       " 'manager',\n",
       " 'software',\n",
       " 'network',\n",
       " 'product',\n",
       " 'intern',\n",
       " 'sales',\n",
       " 'technical',\n",
       " 'director']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model_2.wv.index_to_key[1:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7855dbfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9161561"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.wv.similarity('developer', 'engineer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116bb84d",
   "metadata": {},
   "source": [
    "###### The results aren't that bad but we have to use single words to get the similarity to work. This works well but it is not the solution to our problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded78077",
   "metadata": {},
   "source": [
    "###### Conclusion: Best result: Doc2Vec, Not so best: Word2Vec custom, So-So: Word2Vec pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fe7c60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
